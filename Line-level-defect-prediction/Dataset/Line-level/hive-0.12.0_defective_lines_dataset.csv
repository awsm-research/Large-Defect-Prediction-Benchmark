File,Line_number,SRC
shims/src/common/java/org/apache/hadoop/fs/ProxyFileSystem.java,48,private Path swizzleParamPath(Path p) {
shims/src/common/java/org/apache/hadoop/fs/ProxyFileSystem.java,60,"private FileStatus swizzleFileStatus(FileStatus orig, boolean isParam) {"
shims/src/common/java/org/apache/hadoop/fs/ProxyLocalFileSystem.java,64,"fs = new ProxyFileSystem(localFs, URI.create(proxyUriString));"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/transfer/impl/HCatInputFormatReader.java,66,"job, re.getDbName(), re.getTableName()).setFilter(re.getFilterString());"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,44,@Deprecated
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,45,"public static void setInput(Job job, InputJobInfo inputJobInfo) throws IOException {"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,46,"setInput(job.getConfiguration(), inputJobInfo);"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,52,@Deprecated
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,53,"public static void setInput(Configuration conf, InputJobInfo inputJobInfo) throws IOException {"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,54,"setInput(conf, inputJobInfo.getDatabaseName(), inputJobInfo.getTableName())"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,55,.setFilter(inputJobInfo.getFilter())
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,56,.setProperties(inputJobInfo.getProperties());
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,62,"public static HCatInputFormat setInput(Job job, String dbName, String tableName) throws IOException {"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,63,"return setInput(job.getConfiguration(), dbName, tableName);"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,74,"public static HCatInputFormat setInput(Configuration conf, String dbName, String tableName)"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/HCatInputFormat.java,82,"hCatInputFormat.inputJobInfo = InputJobInfo.create(dbName, tableName, null, null);"
hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatMapReduceTest.java,344,"HCatInputFormat.setInput(job, dbName, tableName).setFilter(filter);"
hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hive/hcatalog/pig/HCatLoader.java,119,"HCatInputFormat.setInput(job, dbName, tableName).setFilter(getPartitionFilterString());"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hcatalog/utils/HBaseReadWrite.java,168,"HCatInputFormat.setInput(job, InputJobInfo.create(dbName, tableName,"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hcatalog/utils/HBaseReadWrite.java,169,null));
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/GroupByAge.java,108,"HCatInputFormat.setInput(job, InputJobInfo.create(dbName,"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/GroupByAge.java,109,"inputTableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadJson.java,93,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadJson.java,94,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadRC.java,94,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadRC.java,95,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadText.java,105,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadText.java,106,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadWrite.java,89,"HCatInputFormat.setInput(job, InputJobInfo.create(dbName,"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/ReadWrite.java,90,"inputTableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/SimpleRead.java,90,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/SimpleRead.java,91,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/StoreComplex.java,106,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/StoreComplex.java,107,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/StoreDemo.java,117,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/StoreDemo.java,118,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/StoreNumbers.java,181,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/StoreNumbers.java,182,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/SumNumbers.java,165,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/SumNumbers.java,166,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/TypeDataCheck.java,153,"HCatInputFormat.setInput(job, InputJobInfo.create("
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/TypeDataCheck.java,154,"dbName, tableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteJson.java,94,"HCatInputFormat.setInput(job, InputJobInfo.create(dbName,"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteJson.java,95,"inputTableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteRC.java,96,"HCatInputFormat.setInput(job, InputJobInfo.create(dbName,"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteRC.java,97,"inputTableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteText.java,106,"HCatInputFormat.setInput(job, InputJobInfo.create(dbName,"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteText.java,107,"inputTableName, null));"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteTextPartitioned.java,97,"HCatInputFormat.setInput(job, InputJobInfo.create(dbName,"
hcatalog/src/test/e2e/hcatalog/udfs/java/org/apache/hive/hcatalog/utils/WriteTextPartitioned.java,98,"inputTableName, filter));"
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/TestHBaseInputFormat.java,163,"InputJobInfo inputJobInfo = InputJobInfo.create(databaseName, tableName,"
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/TestHBaseInputFormat.java,164,null);
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/TestHBaseInputFormat.java,165,"HCatInputFormat.setInput(job, inputJobInfo);"
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/TestHBaseInputFormat.java,231,"HCatInputFormat.setInput(job, inputJobInfo);"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3439,"groupByOutputRowResolver.putExpression(value, new ColumnInfo("
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3440,"field, udaf.returnType, """", false));"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,5010,"ltd = new LoadTableDesc(queryTmpdir, ctx.getExternalTmpFileURI(dest_path.toUri()),"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,5094,"ltd = new LoadTableDesc(queryTmpdir, ctx.getExternalTmpFileURI(dest_path.toUri()),"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,5216,"loadFileWork.add(new LoadFileDesc(tblDesc, queryTmpdir, destStr, isDfsDir, cols,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,5074,Path partPath = dest_part.getPartitionPath();
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,9027,crtTblDesc.validate();
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,8351,resultSchema =
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,8352,convertRowSchemaToViewSchema(opParseCtx.get(sinkOp).getRowResolver());
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,8534,private List<FieldSchema> convertRowSchemaToViewSchema(RowResolver rr) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,8540,String colName = rr.reverseLookup(colInfo.getInternalName())[1];
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,8541,"fieldSchemas.add(new FieldSchema(colName,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,8542,"colInfo.getType().getTypeName(), null));"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,213,private final GlobalLimitCtx globalLimitCtx = new GlobalLimitCtx();
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,224,"private final Map<String, ReadEntity> viewAliasToInput = new HashMap<String, ReadEntity>();"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,227,private static final int AUTOGEN_COLALIAS_PRFX_MAXLENGTH = 20;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,230,protected boolean noscan = false;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,233,protected boolean partialscan = false;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,185,"private LinkedHashMap<Operator<? extends OperatorDesc>, OpParseContext> opParseCtx;"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3197,boolean partialAggDone = !(distPartAgg || isDistinct);
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3198,if (!partialAggDone) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3252,if (distPartAgg) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3253,"genericUDAFEvaluator = getGenericUDAFEvaluator(aggName, aggParameters,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3254,"value, isDistinct, isAllColumns);"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,2982,assert (genericUDAFEvaluator != null);
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3444,"genericUDAFEvaluators.put(entry.getKey(), genericUDAFEvaluator);"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3526,} else {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3258,genericUDAFEvaluator = genericUDAFEvaluators.get(entry.getKey());
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3944,assert (genericUDAFEvaluator != null);
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,3284,"distPartAgg, groupByMemoryUsage, memoryThreshold,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,4525,"genericUDAFEvaluators, false,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,4538,"genericUDAFEvaluators, false,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,4669,"genericUDAFEvaluators, false,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7252,if (conf.getBoolVar(HiveConf.ConfVars.HIVEMULTIGROUPBYSINGLEREDUCER)) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,10305,try {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7254,"commonGroupByDestGroups = getCommonGroupByDestGroups(qb, inputs);"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7255,} catch (SemanticException e) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7256,"LOG.error(""Failed to group clauses by common spray keys."", e);"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7316,"curr = genGroupByPlan1MR(dest, qb, curr);"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7508,"for (Map.Entry<String, ColumnInfo> lEntry : leftmap.entrySet()) {"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7509,String field = lEntry.getKey();
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7511,ColumnInfo rInfo = rightmap.get(field);
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7475,if (rInfo == null) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7476,"throw new SemanticException(generateErrorMessage(tabref,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7477,"""Schema of both sides of union should match. "" + rightalias"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7483,"+ "" does not have the field "" + field));"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7480,if (lInfo == null) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7481,"throw new SemanticException(generateErrorMessage(tabref,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7482,"""Schema of both sides of union should match. "" + leftalias"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7478,"+ "" does not have the field "" + field));"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7485,if (!lInfo.getInternalName().equals(rInfo.getInternalName())) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7498,"throw new SemanticException(generateErrorMessage(tabref,"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7487,"""Schema of both sides of union should match: field "" + field + "":"""
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7488,"+ "" appears on the left side of the UNION at column position: "" +"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7489,getPositionFromInternalName(lInfo.getInternalName())
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7490,"+ "", and on the right side of the UNION at column position: "" +"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7491,getPositionFromInternalName(rInfo.getInternalName())
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7492,"+ "". Column positions should match for a UNION""));"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7612,"for (Map.Entry<String, ColumnInfo> unionEntry : unionoutRR.getFieldMap(unionalias).entrySet()) {"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7613,String field = unionEntry.getKey();
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7614,ColumnInfo lInfo = origInputFieldMap.get(field);
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7615,"ExprNodeDesc column = new ExprNodeColumnDesc(lInfo.getType(), lInfo.getInternalName(),"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7616,"lInfo.getTabAlias(), lInfo.getIsVirtualCol(), lInfo.isSkewedCol());"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7617,if (!lInfo.getType().equals(unionEntry.getValue().getType())) {
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,7620,"column, (PrimitiveTypeInfo)unionEntry.getValue().getType());"
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,1275,CreateTableDesc localDirectoryDesc = new CreateTableDesc();
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,1276,boolean localDirectoryDescIsSet = false;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,1310,if (localDirectoryDescIsSet){
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,1311,qb.setLocalDirectoryDesc(localDirectoryDesc);
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzer.java,5224,"table_desc = PlanUtils.getDefaultTableDesc(qb.getLLocalDirectoryDesc(), cols, colTypes);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HDFSStorage.java,107,"LOG.info(""Couldn't find "" + p + "": "" + e.getMessage());"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/HiveJobIDParser.java,35,"return parseJobID(TempletonControllerJob.STDERR_FNAME, jobidPattern);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/JarJobIDParser.java,35,"return parseJobID(TempletonControllerJob.STDERR_FNAME, jobidPattern);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/PigJobIDParser.java,35,"return parseJobID(TempletonControllerJob.STDERR_FNAME, jobidPattern);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,21,import java.io.BufferedReader;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,23,import java.io.InputStream;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,24,import java.io.InputStreamReader;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,25,import java.io.OutputStream;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,26,import java.io.PrintWriter;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,27,import java.net.URISyntaxException;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,59,import org.apache.hive.hcatalog.templeton.BadParam;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,60,import org.apache.hive.hcatalog.templeton.LauncherDelegator;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,74,public class TempletonControllerJob extends Configured implements Tool {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,75,"public static final String COPY_NAME = ""templeton.copy"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,76,"public static final String STATUSDIR_NAME = ""templeton.statusdir"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,77,"public static final String ENABLE_LOG = ""templeton.enablelog"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,78,"public static final String JOB_TYPE = ""templeton.jobtype"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,79,"public static final String JAR_ARGS_NAME = ""templeton.args"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,80,"public static final String OVERRIDE_CLASSPATH = ""templeton.override-classpath"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,82,"public static final String STDOUT_FNAME = ""stdout"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,83,"public static final String STDERR_FNAME = ""stderr"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,84,"public static final String EXIT_FNAME = ""exit"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,86,public static final int WATCHER_TIMEOUT_SECS = 10;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,87,public static final int KEEP_ALIVE_MSEC = 60 * 1000;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,89,public static final String TOKEN_FILE_ARG_PLACEHOLDER
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,90,"= ""__WEBHCAT_TOKEN_FILE_LOCATION__"";"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,93,private static TrivialExecService execService = TrivialExecService.getInstance();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,163,@Override
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,164,public void run(Context context)
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,165,"throws IOException, InterruptedException {"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,167,Configuration conf = context.getConfiguration();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,169,"Process proc = startJob(context,"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,170,"conf.get(""user.name""),"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,171,conf.get(OVERRIDE_CLASSPATH));
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,173,String statusdir = conf.get(STATUSDIR_NAME);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,175,if (statusdir != null) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,176,try {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,177,"statusdir = TempletonUtils.addUserHomeDirectoryIfApplicable(statusdir,"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,178,"conf.get(""user.name""));"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,179,} catch (URISyntaxException e) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,180,"throw new IOException(""Invalid status dir URI"", e);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,288,String percent = TempletonUtils.extractPercentComplete(line);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,289,String childid = TempletonUtils.extractChildJobId(line);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,291,if (percent != null || childid != null) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,292,"state = new JobState(jobid.toString(), conf);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,293,state.setPercentComplete(percent);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,294,state.setChildId(childid);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,296,} catch (IOException e) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,297,"System.err.println(""templeton: state error: "" + e);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,298,} finally {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,299,if (state != null) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,300,try {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,301,state.close();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,302,} catch (IOException e) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,314,public static class KeepAlive implements Runnable {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,315,private Context context;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,316,public boolean sendReport;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,318,public KeepAlive(Context context)
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,320,this.sendReport = true;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,321,this.context = context;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,324,@Override
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,325,public void run() {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,326,try {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,327,while (sendReport) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,331,context.progress();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,332,"System.err.println(""KeepAlive Heart beat"");"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,333,Thread.sleep(KEEP_ALIVE_MSEC);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,335,} catch (InterruptedException e) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,360,job.setJarByClass(TempletonControllerJob.class);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonControllerJob.java,361,"job.setJobName(""TempletonControllerJob"");"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonUtils.java,89,public static final Pattern JAR_COMPLETE
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TempletonUtils.java,90,"= Pattern.compile("" map \\d+%\\s+reduce \\d+%$"");"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,32,public class TrivialExecService {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,33,private static volatile TrivialExecService theSingleton;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,46,"Map<String, String> environmentVariables)"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,48,"logDebugCmd(cmd, environmentVariables);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,50,for (String key : removeEnv)
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,56,"private void logDebugCmd(List<String> cmd,"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,57,"Map<String, String> environmentVariables) {"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,58,if(!LOG.isDebugEnabled()){
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,59,return;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,61,"LOG.debug(""starting "" + cmd);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,62,"LOG.debug(""With environment variables: "" );"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,63,"for(Map.Entry<String, String> keyVal : environmentVariables.entrySet()){"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,64,"LOG.debug(keyVal.getKey() + ""="" + keyVal.getValue());"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,66,"LOG.debug(""With environment variables already set: "" );"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,67,"Map<String, String> env = System.getenv();"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,68,for (String envName : env.keySet()) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/tool/TrivialExecService.java,69,"LOG.debug(envName + ""="" + env.get(envName));"
hcatalog/webhcat/svr/src/test/java/org/apache/hive/hcatalog/templeton/tool/TestTrivialExecService.java,41,"new HashMap<String, String>());"
shims/src/0.20S/java/org/apache/hadoop/mapred/WebHCatJTShim20S.java,91,public void close() {
shims/src/0.20S/java/org/apache/hadoop/mapred/WebHCatJTShim20S.java,92,RPC.stopProxy(cnx);
shims/src/0.20S/java/org/apache/hadoop/mapred/WebHCatJTShim20S.java,94,private InetSocketAddress getAddress(Configuration conf) {
shims/src/0.20S/java/org/apache/hadoop/mapred/WebHCatJTShim20S.java,95,"String jobTrackerStr = conf.get(""mapred.job.tracker"", ""localhost:8012"");"
shims/src/0.20S/java/org/apache/hadoop/mapred/WebHCatJTShim20S.java,96,return NetUtils.createSocketAddr(jobTrackerStr);
service/src/java/org/apache/hive/service/cli/operation/ExecuteStatementOperation.java,35,this.confOverlay = confOverlay;
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,83,private void runInternal() throws HiveSQLException {
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,100,"String subStatement = new VariableSubstitution().substitute(getParentSession().getHiveConf(), statement);"
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,145,runInternal();
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,153,runInternal();
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,151,SessionState.start(ss);
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,102,response = driver.run(subStatement);
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,104,"throw new HiveSQLException(""Error while processing statement: """
service/src/java/org/apache/hive/service/cli/operation/SQLOperation.java,115,"throw new HiveSQLException(""Error running query: Schema and FieldSchema "" +"
jdbc/src/java/org/apache/hive/jdbc/HiveBaseResultSet.java,618,"throw new SQLException(""Method not supported"");"
jdbc/src/java/org/apache/hive/jdbc/HiveCallableStatement.java,53,public HiveCallableStatement() {
jdbc/src/java/org/apache/hive/jdbc/HiveCallableStatement.java,1390,return new HiveQueryResultSet.Builder().build();
jdbc/src/java/org/apache/hive/jdbc/HiveCallableStatement.java,2173,"throw new SQLException(""Method not supported"");"
jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java,418,"return new HiveStatement(client, sessHandle);"
jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java,517,"return new HiveDatabaseMetaData(client, sessHandle);"
jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java,646,"return new HivePreparedStatement(client, sessHandle, sql);"
jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java,657,"return new HivePreparedStatement(client, sessHandle, sql);"
jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java,693,"return new HivePreparedStatement(client, sessHandle, sql);"
jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java,134,configureConnection();
jdbc/src/java/org/apache/hive/jdbc/HiveConnection.java,252,private void configureConnection() throws SQLException {
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,70,"public HiveDatabaseMetaData(TCLIService.Iface client, TSessionHandle sessHandle) {"
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,131,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,215,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,244,"throw new SQLException(""Method not supported"");"
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,330,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,343,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,485,return new HiveQueryResultSet.Builder().setClient(client).setEmptyResultSet(true).
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,496,return new HiveQueryResultSet.Builder().setClient(client).setEmptyResultSet(true).
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,517,return new HiveQueryResultSet.Builder().setClient(client).setEmptyResultSet(true).
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,571,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,615,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,648,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,704,return new HiveQueryResultSet.Builder()
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,1126,"HiveDatabaseMetaData meta = new HiveDatabaseMetaData(null, null);"
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,637,if (schemaPattern != null) {
jdbc/src/java/org/apache/hive/jdbc/HiveDatabaseMetaData.java,638,getTableReq.setSchemaName(schemaPattern);
jdbc/src/java/org/apache/hive/jdbc/HivePreparedStatement.java,58,"public HivePreparedStatement(TCLIService.Iface client, TSessionHandle sessHandle,"
jdbc/src/java/org/apache/hive/jdbc/HivePreparedStatement.java,59,String sql) {
jdbc/src/java/org/apache/hive/jdbc/HivePreparedStatement.java,60,"super(client, sessHandle);"
jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java,255,if (hiveStatement != null) {
jdbc/src/java/org/apache/hive/jdbc/HiveQueryResultSet.java,256,hiveStatement.closeClientOperation();
jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java,79,"public HiveStatement(TCLIService.Iface client, TSessionHandle sessHandle) {"
jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java,247,resultSet =  new HiveQueryResultSet.Builder().setClient(client).setSessionHandle(sessHandle)
jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java,248,.setStmtHandle(stmtHandle).setHiveStatement(this).setMaxRows(maxRows).setFetchSize(fetchSize)
jdbc/src/java/org/apache/hive/jdbc/HiveStatement.java,354,"throw new SQLException(""Method not supported"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMod.java,45,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMod.java,57,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMod.java,69,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMod.java,81,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMod.java,93,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFOPMod.java,105,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFPosMod.java,46,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFPosMod.java,58,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFPosMod.java,70,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFPosMod.java,82,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFPosMod.java,94,if ((a == null) || (b == null)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/UDFPosMod.java,106,if ((a == null) || (b == null)) {
service/src/test/org/apache/hive/service/cli/TestEmbeddedThriftBinaryCLIService.java,34,private static ThriftCLIService service;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DeleteDelegator.java,50,String childid = state.getChildId();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DeleteDelegator.java,51,if (childid != null)
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/DeleteDelegator.java,52,tracker.killJob(StatusDelegator.StringToJobID(childid));
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,53,JobState state = null;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,54,try {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,55,String id = job.getJobID().toString();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,56,"state = new JobState(id, Main.getAppConfigInstance());"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,57,if (showall || user.equals(state.getUser()))
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,58,ids.add(id);
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,59,} finally {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,60,if (state != null) {
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/ListDelegator.java,61,state.close();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java,60,parentId = state.getId();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java,61,if (id.equals(parentId))
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java,62,parentId = null;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/QueueStatusBean.java,65,user = state.getUser();
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StatusDelegator.java,66,"public static QueueStatusBean makeStatus(WebHCatJTShim tracker,"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/StatusDelegator.java,88,"throw new BadParam(""Could not find job "" + bestid);"
ql/src/java/org/apache/hadoop/hive/ql/session/SessionState.java,257,tss.set(startSs);
service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java,111,SessionState.start(sessionState);
service/src/java/org/apache/hive/service/cli/session/HiveSessionImpl.java,67,private final SessionState sessionState;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/HiveDelegator.java,128,"args.add(""-archives"");"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java,73,"if (appConf.pigArchive() != null && !appConf.pigArchive().equals(""""))"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java,75,"args.add(""-archives"");"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/PigDelegator.java,76,args.add(appConf.pigArchive());
hcatalog/core/src/main/java/org/apache/hive/hcatalog/cli/HCatCli.java,129,"printUsage(options, ss.err);"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/cli/HCatCli.java,133,String execString = (String) cmdLine.getOptionValue('e');
hcatalog/core/src/main/java/org/apache/hive/hcatalog/cli/HCatCli.java,135,String fileName = (String) cmdLine.getOptionValue('f');
hcatalog/core/src/main/java/org/apache/hive/hcatalog/cli/HCatCli.java,161,"setConfProperties(conf, cmdLine.getOptionProperties(""D""));"
ql/src/java/org/apache/hadoop/hive/ql/security/HadoopDefaultAuthenticator.java,31,private String userName;
ql/src/java/org/apache/hadoop/hive/ql/security/HadoopDefaultAuthenticator.java,32,private List<String> groupNames;
ql/src/java/org/apache/hadoop/hive/ql/security/HadoopDefaultAuthenticator.java,34,private Configuration conf;
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,96,private static String getQuorumServers(HiveConf conf) {
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,97,String hosts = conf.getVar(HiveConf.ConfVars.HIVE_ZOOKEEPER_QUORUM);
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,99,"return hosts + "":"" + port;"
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,453,HiveLockObject obj = zLock.getHiveLockObject();
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,454,"String name  = getLastObjectName(parent, obj);"
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,456,try {
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,457,"List<String> children = zkpClient.getChildren(name, false);"
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,458,if (children == null || children.isEmpty()) {
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,459,"zkpClient.delete(name, -1);"
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,461,} catch (KeeperException.NoNodeException e) {
ql/src/java/org/apache/hadoop/hive/ql/lockmgr/zookeeper/ZooKeeperHiveLockManager.java,462,"LOG.debug(""Node "" + name + "" previously deleted when attempting to delete."");"
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,46,"private final Map<SessionHandle, HiveSession> handleToSession = new HashMap<SessionHandle, HiveSession>();"
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,47,private OperationManager operationManager = new OperationManager();
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,48,private static final Object sessionMapLock = new Object();
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,110,synchronized(sessionMapLock) {
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,111,"handleToSession.put(session.getSessionHandle(), session);"
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,122,HiveSession session;
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,123,synchronized(sessionMapLock) {
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,124,session = handleToSession.remove(sessionHandle);
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,134,HiveSession session;
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,135,synchronized(sessionMapLock) {
service/src/java/org/apache/hive/service/cli/session/SessionManager.java,136,session = handleToSession.get(sessionHandle);
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java,234,conf.getBoolVar(HiveConf.ConfVars.HIVE_SERVER2_ENABLE_DOAS) == true
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/MapredLocalTask.java,467,"BucketMatcher bucketMatcher = (BucketMatcher) ReflectionUtils.newInstance(bucketMatcherCls,"
ql/src/java/org/apache/hadoop/hive/ql/plan/ExprNodeGenericFuncDesc.java,121,sb.append(genericUDF.getClass().toString());
ql/src/test/org/apache/hadoop/hive/ql/io/TestRCFile.java,137,"patialS.set(5, new BytesRefWritable(""NULL"".getBytes(""UTF-8"")));"
ql/src/test/org/apache/hadoop/hive/ql/io/TestRCFile.java,139,"patialS.set(7, new BytesRefWritable(""NULL"".getBytes(""UTF-8"")));"
serde/src/java/org/apache/hadoop/hive/serde2/columnar/BytesRefArrayWritable.java,142,if (other.contains(bytesRefWritables[i])) {
serde/src/java/org/apache/hadoop/hive/serde2/columnar/BytesRefArrayWritable.java,143,continue;
serde/src/java/org/apache/hadoop/hive/serde2/columnar/BytesRefArrayWritable.java,144,} else {
serde/src/java/org/apache/hadoop/hive/serde2/columnar/BytesRefArrayWritable.java,145,return 1;
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,887,public CommandProcessorResponse run(String command) throws CommandNeedRetryException {
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,888,CommandProcessorResponse cpr = runInternal(command);
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,943,private CommandProcessorResponse runInternal(String command) throws CommandNeedRetryException {
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,976,synchronized (compileMonitor) {
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,977,ret = compile(command);
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,979,if (ret != 0) {
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,1562,releaseLocks(ctx.getHiveLocks());
ql/src/java/org/apache/hadoop/hive/ql/Driver.java,981,"return new CommandProcessorResponse(ret, errorMessage, SQLState);"
service/src/test/org/apache/hive/service/cli/CLIServiceTest.java,155,OperationHandle ophandle;
service/src/test/org/apache/hive/service/cli/CLIServiceTest.java,171,"String wrongQueryString = ""SELECT NAME FROM TEST_EXEC"";"
service/src/test/org/apache/hive/service/cli/CLIServiceTest.java,172,"ophandle = client.executeStatementAsync(sessionHandle, wrongQueryString, confOverlay);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,292,double xavgOld = myagg.xavg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,293,double yavgOld = myagg.yavg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,295,myagg.xavg += (vx - xavgOld) / myagg.count;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,296,myagg.yavg += (vy - yavgOld) / myagg.count;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,298,myagg.covar += (vx - xavgOld) * (vy - myagg.yavg);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,299,myagg.xvar += (vx - xavgOld) * (vx - myagg.xavg);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,300,myagg.yvar += (vy - yavgOld) * (vy - myagg.yavg);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,355,myagg.xvar += xvarB + (xavgA - xavgB) * (xavgA - xavgB) * myagg.count;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFCorrelation.java,356,myagg.yvar += yvarB + (yavgA - yavgB) * (yavgA - yavgB) * myagg.count;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,436,if (start < 0) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,440,"ByteBuffer src = ByteBuffer.wrap(text.getBytes(), 0, text.getLength());"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,441,ByteBuffer tgt = ByteBuffer
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,442,".wrap(subtext.getBytes(), 0, subtext.getLength());"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,443,byte b = tgt.get();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,444,src.position(start);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,446,while (src.hasRemaining()) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,447,if (b == src.get()) { // matching first byte
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,448,src.mark(); // save position in loop
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,449,tgt.mark(); // save position in target
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,450,boolean found = true;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,451,int pos = src.position() - 1;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,452,while (tgt.hasRemaining()) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,453,if (!src.hasRemaining()) { // src expired first
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,454,tgt.reset();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,455,src.reset();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,456,found = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,457,break;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,459,if (!(tgt.get() == src.get())) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,460,tgt.reset();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,461,src.reset();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,462,found = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,463,break; // no match
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,466,if (found) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFUtils.java,467,return pos;
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java,90,"args.add(""-D"" + TempletonControllerJob.TOKEN_FILE_ARG_PLACEHOLDER);"
hcatalog/webhcat/svr/src/main/java/org/apache/hive/hcatalog/templeton/JarDelegator.java,94,TempletonUtils.quoteForWindows(d);
ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java,279,if (Utilities.ReduceField.KEY.name().equals(names[0])) {
ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java,742,if (hashAggr && !groupKeyIsNotReduceKey) {
ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java,836,if ((!groupKeyIsNotReduceKey || firstRowInGroup)
ql/src/java/org/apache/hadoop/hive/ql/exec/GroupByOperator.java,837,&& shouldBeFlushed(newKeys)) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java,337,cndTsk
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java,338,.setResolverCtx(new ConditionalResolverSkewJoin.ConditionalResolverSkewJoinCtx(
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java,339,bigKeysDirToTaskMap));
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/GenMRSkewJoinProcessor.java,340,List<Task<? extends Serializable>> oldChildTasks = currTask.getChildTasks();
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverSkewJoin.java,53,"HashMap<String, Task<? extends Serializable>> dirToTaskMap;"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverSkewJoin.java,62,"HashMap<String, Task<? extends Serializable>> dirToTaskMap) {"
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/HCatBaseTest.java,44,"protected static final String TEST_DATA_DIR = System.getProperty(""user.dir"") +"
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/HCatBaseTest.java,45,"""/build/test/data/"" + HCatBaseTest.class.getCanonicalName();"
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestHCatPartitionPublish.java,85,"System.setProperty(""hadoop.log.dir"", new File(fs.getWorkingDirectory()"
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestHCatPartitionPublish.java,86,".toString(), ""/logs"").getAbsolutePath());"
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestMultiOutputFormat.java,70,private static Configuration mrConf = null;
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestMultiOutputFormat.java,85,"mrCluster = new MiniMRCluster(1, fs.getUri().toString(), 1, null, null,"
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestMultiOutputFormat.java,86,new JobConf(conf));
hcatalog/core/src/test/java/org/apache/hcatalog/mapreduce/TestMultiOutputFormat.java,87,mrConf = mrCluster.createJobConf();
hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java,43,protected static final String TEST_DATA_DIR =
hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/HCatBaseTest.java,44,"""/tmp/build/test/data/"" + HCatBaseTest.class.getCanonicalName();"
hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestMultiOutputFormat.java,67,private static Configuration mrConf = null;
hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestMultiOutputFormat.java,82,"mrCluster = new MiniMRCluster(1, fs.getUri().toString(), 1, null, null,"
hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestMultiOutputFormat.java,83,new JobConf(conf));
hcatalog/core/src/test/java/org/apache/hive/hcatalog/mapreduce/TestMultiOutputFormat.java,84,mrConf = mrCluster.createJobConf();
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatLoader.java,425,""" stored as textfile location 'file://"" +"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatLoader.java,426,"inputDataDir.getAbsolutePath() + ""'"").getResponseCode());"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatLoaderStorer.java,72,"dataDir.getAbsolutePath() + ""' into table "" + readTblName).getResponseCode());"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatLoaderStorer.java,107,"smallTinyIntBoundsCheckHelper(writeDataFile.getAbsolutePath(), ExecJob.JOB_STATUS.COMPLETED);"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatStorerMulti.java,44,"private static final String TEST_DATA_DIR = System.getProperty(""user.dir"") +"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatStorerMulti.java,45,"""/build/test/data/"" + TestHCatStorerMulti.class.getCanonicalName();"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatStorerWrapper.java,51,"File tmpExternalDir = new File(SystemUtils.getJavaIoTmpDir(), UUID.randomUUID().toString());"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatStorerWrapper.java,74,"+ ""('c="" + part_val + ""','"" + tmpExternalDir.getAbsolutePath() + ""');"");"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hcatalog/pig/TestHCatStorerWrapper.java,78,"Assert.assertTrue(new File(tmpExternalDir.getAbsoluteFile() + ""/"" + ""part-m-00000"").exists());"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hive/hcatalog/pig/TestHCatLoader.java,422,""" stored as textfile location 'file://"" +"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hive/hcatalog/pig/TestHCatLoader.java,77,"driver.run(""drop table "" + tablename);"
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hive/hcatalog/pig/TestHCatStorerMulti.java,41,private static final String TEST_DATA_DIR =
hcatalog/hcatalog-pig-adapter/src/test/java/org/apache/hive/hcatalog/pig/TestHCatStorerMulti.java,42,"""/tmp/build/test/data/"" + TestHCatStorerMulti.class.getCanonicalName();"
hcatalog/storage-handlers/hbase/src/test/org/apache/hcatalog/hbase/SkeletonHBaseTest.java,175,try {
hcatalog/storage-handlers/hbase/src/test/org/apache/hcatalog/hbase/SkeletonHBaseTest.java,176,"testDir = new File(TEST_DIR + ""/test_"" + handle + ""_"" + Math.abs(new Random().nextLong()) + ""/"").getCanonicalPath();"
hcatalog/storage-handlers/hbase/src/test/org/apache/hcatalog/hbase/SkeletonHBaseTest.java,177,"System.out.println(""Cluster work directory: "" + testDir);"
hcatalog/storage-handlers/hbase/src/test/org/apache/hcatalog/hbase/SkeletonHBaseTest.java,178,} catch (IOException e) {
hcatalog/storage-handlers/hbase/src/test/org/apache/hcatalog/hbase/SkeletonHBaseTest.java,179,"throw new IllegalStateException(""Failed to generate testDir"", e);"
hcatalog/storage-handlers/hbase/src/test/org/apache/hcatalog/hbase/TestHCatHBaseInputFormat.java,66,import org.apache.hcatalog.common.HCatUtil;
hcatalog/storage-handlers/hbase/src/test/org/apache/hcatalog/hbase/TestHCatHBaseInputFormat.java,184,"String db_dir = getTestDir() + ""/hbasedb"";"
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/SkeletonHBaseTest.java,175,try {
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/SkeletonHBaseTest.java,176,"testDir = new File(TEST_DIR + ""/test_"" + handle + ""_"" + Math.abs(new Random().nextLong()) + ""/"").getCanonicalPath();"
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/SkeletonHBaseTest.java,177,"System.out.println(""Cluster work directory: "" + testDir);"
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/SkeletonHBaseTest.java,178,} catch (IOException e) {
hcatalog/storage-handlers/hbase/src/test/org/apache/hive/hcatalog/hbase/SkeletonHBaseTest.java,179,"throw new IllegalStateException(""Failed to generate testDir"", e);"
ql/src/java/org/apache/hadoop/hive/ql/exec/CopyTask.java,54,Path fromPath = new Path(work.getFromPath());
ql/src/java/org/apache/hadoop/hive/ql/exec/CopyTask.java,55,toPath = new Path(work.getToPath());
ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java,254,dirs = fs.globStatus(new Path(tbd.getSourceDir()));
ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java,253,"fs = FileSystem.get(table.getDataLocation(), conf);"
ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java,462,FileSystem fileSys = partn.getPartitionPath().getFileSystem(conf);
ql/src/java/org/apache/hadoop/hive/ql/exec/MoveTask.java,464,"partn.getPartitionPath(), 1, fileSys);"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRFileSink1.java,351,"new LoadFileDesc(fsInputDesc.getFinalDirName(), finalName, true, null, null), false);"
ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java,985,"LoadTableDesc ltd = new LoadTableDesc(queryTmpdir, queryTmpdir, tblDesc,"
ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java,1599,"LoadTableDesc ltd = new LoadTableDesc(queryTmpdir, queryTmpdir, tblDesc,"
ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java,901,Path partPath = part.getPartitionPath();
ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java,1544,Path partPath = part.getPartitionPath();
ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java,2937,"LOG.error(""Got HiveException during obtaining list of partitions"");"
ql/src/java/org/apache/hadoop/hive/ql/parse/DDLSemanticAnalyzer.java,2947,"LOG.debug(""Wrong specification"");"
ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java,94,"path.toString(), toURI.toString(), false), conf);"
ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java,109,"new CopyWork(fromURI.toString(), toPartPath.toString(), false),"
ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java,118,"fromURI.toString(), toDataPath.toString(), false), conf);"
ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java,106,URI fromURI = partition.getDataLocation();
ql/src/java/org/apache/hadoop/hive/ql/parse/ExportSemanticAnalyzer.java,115,URI fromURI = ts.tableHandle.getDataLocation();
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,284,String tmpURI = ctx.getExternalTmpFileURI(fromURI);
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,285,"Task<?> copyTask = TaskFactory.get(new CopyWork(dataPath.toString(),"
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,286,"tmpURI, false), conf);"
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,287,"LoadTableDesc loadTableWork = new LoadTableDesc(tmpURI.toString(),"
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,329,String tmpURI = ctx.getExternalTmpFileURI(fromURI);
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,330,"Task<?> copyTask = TaskFactory.get(new CopyWork(srcLocation,"
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,331,"tmpURI, false), conf);"
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,334,"LoadTableDesc loadTableWork = new LoadTableDesc(tmpURI,"
ql/src/java/org/apache/hadoop/hive/ql/parse/ImportSemanticAnalyzer.java,404,.equals(new URI(tableDesc.getLocation()))) {
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,87,"path = URIUtil.decode( new Path(System.getProperty(""user.dir""), path).toUri().toString() );"
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,128,"FileStatus[] srcs = matchFilesOrDir(FileSystem.get(fromURI, conf),"
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,129,"new Path(fromURI.getScheme(), fromURI.getAuthority(), fromURI"
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,130,.getPath()));
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,236,try {
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,237,"rTask = TaskFactory.get(new CopyWork(URIUtil.decode(fromURI.toString()), copyURIStr),"
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,238,conf);
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,239,} catch (URIException e) {
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,240,"throw new SemanticException(ErrorMsg.INVALID_PATH.getMsg(fromTree, e"
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,241,".getMessage()), e);"
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,272,try {
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,273,"loadTableWork = new LoadTableDesc(URIUtil.decode(fromURI.toString()),"
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,214,URI toURI = (ts.partHandle != null) ? ts.partHandle.getDataLocation()
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,215,: ts.tableHandle.getDataLocation();
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,66,FileStatus[] srcs = fs.globStatus(path);
ql/src/java/org/apache/hadoop/hive/ql/parse/LoadSemanticAnalyzer.java,69,srcs = fs.listStatus(srcs[0].getPath());
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,30,private String fromPath;
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,31,private String toPath;
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,37,"public CopyWork(final String fromPath, final String toPath) {"
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,41,"public CopyWork(final String fromPath, final String toPath, boolean errorOnSrcEmpty) {"
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,48,public String getFromPath() {
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,49,return fromPath;
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,52,public void setFromPath(final String fromPath) {
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,53,this.fromPath = fromPath;
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,56,"@Explain(displayName = ""destination"")"
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,57,public String getToPath() {
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,58,return toPath;
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,61,public void setToPath(final String toPath) {
ql/src/java/org/apache/hadoop/hive/ql/plan/CopyWork.java,62,this.toPath = toPath;
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadDesc.java,29,private String sourceDir;
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadDesc.java,34,public LoadDesc(final String sourceDir) {
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadDesc.java,36,this.sourceDir = sourceDir;
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadDesc.java,41,return sourceDir;
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadDesc.java,44,public void setSourceDir(final String source) {
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadDesc.java,45,sourceDir = source;
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadFileDesc.java,39,"public LoadFileDesc(final CreateTableDesc createTableDesc, final String sourceDir,"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadFileDesc.java,42,"this(sourceDir, targetDir, isDfsDir, columns, columnTypes);"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadFileDesc.java,51,"public LoadFileDesc(final String sourceDir, final String targetDir,"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadFileDesc.java,54,super(sourceDir);
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,48,"public LoadTableDesc(final String sourceDir, final String tmpDir,"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,51,super(sourceDir);
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,52,"init(sourceDir, tmpDir, table, partitionSpec, replace);"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,55,"public LoadTableDesc(final String sourceDir, final String tmpDir,"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,58,"this(sourceDir, tmpDir, table, partitionSpec, true);"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,61,"public LoadTableDesc(final String sourceDir, final String tmpDir,"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,64,super(sourceDir);
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,67,"init(sourceDir, tmpDir, table, dpCtx.getPartSpec(), true);"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,69,"init(sourceDir, tmpDir, table, new LinkedHashMap<String, String>(), true);"
ql/src/java/org/apache/hadoop/hive/ql/plan/LoadTableDesc.java,73,"private void init(final String sourceDir, final String tmpDir,"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java,952,String origStreamDesc;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java,953,"streamDesc = ""$INTNAME"";"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMapRedUtils.java,954,origStreamDesc = streamDesc;
ql/src/java/org/apache/hadoop/hive/ql/udf/UDAFPercentile.java,62,return o1.getKey().compareTo(o2.getKey());
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,174,int fpos;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,175,try {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,176,fpos = s.getPosition(fieldName);
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,177,} catch (NullPointerException npe) {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,179,"LOG.debug(""NPE finding position for field [{}] in schema [{}]"", fieldName, s);"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,183,throw npe;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,185,if (fpos == -1) {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/JsonSerDe.java,186,"return; // unknown field, we return."
hcatalog/core/src/main/java/org/apache/hcatalog/cli/SemanticAnalysis/CreateTableHook.java,219,table.setDataLocation(new Path(desc.getLocation()).toUri());
hcatalog/core/src/main/java/org/apache/hcatalog/security/HdfsAuthorizationProvider.java,211,"authorize(part.getPartitionPath(), readRequiredPriv, writeRequiredPriv);"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/cli/SemanticAnalysis/CreateTableHook.java,216,table.setDataLocation(new Path(desc.getLocation()).toUri());
ql/src/java/org/apache/hadoop/hive/ql/exec/ArchiveUtils.java,111,URI tableDir = tbl.getDataLocation();
ql/src/java/org/apache/hadoop/hive/ql/exec/ArchiveUtils.java,115,"return new Path(tableDir.toString(), prefixSubdir);"
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,936,FileSystem fs = p.getPartitionPath().getFileSystem(db.getConf());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,937,FileStatus fss = fs.getFileStatus(p.getPartitionPath());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,1265,URI tableDir = tbl.getDataLocation();
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,1270,"String standardLocation = (new Path(tableDir.toString(), subdir)).toString();"
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,1319,originalDir = p.getPartitionPath();
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,1471,URI originalPartitionUri = ArchiveUtils.addSlash(p.getPartitionPath().toUri());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,1472,URI test = p.getPartitionPath().toUri();
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,3144,tbl.setDataLocation(locUri);
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,3597,tbl.setDataLocation(new Path(crtTbl.getLocation()).toUri());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,3735,tbl.setDataLocation(new Path(crtTbl.getLocation()).toUri());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,3889,locations.add(partition.getPartitionPath());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,3896,locations.add(partition.getPartitionPath());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,2827,if (!descTbl.isFormatted()) {
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,2828,if (tableName.equals(colPath)) {
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,2829,cols.addAll(tbl.getPartCols());
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,3073,"tbl.setFields(Hive.getFieldsFromDeserializer(tbl.getTableName(), tbl."
ql/src/java/org/apache/hadoop/hive/ql/exec/DDLTask.java,3074,getDeserializer()));
ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java,227,return t.getDataLocation();
ql/src/java/org/apache/hadoop/hive/ql/hooks/Entity.java,231,return p.getDataLocation();
ql/src/java/org/apache/hadoop/hive/ql/index/IndexMetadataChangeTask.java,70,Path url = new Path(part.getPartitionPath().toString());
ql/src/java/org/apache/hadoop/hive/ql/index/IndexMetadataChangeTask.java,71,FileSystem fs = url.getFileSystem(conf);
ql/src/java/org/apache/hadoop/hive/ql/index/IndexMetadataChangeTask.java,72,FileStatus fstat = fs.getFileStatus(url);
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1192,oldPartPath = oldPart.getPartitionPath();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1198,"Path partPath = new Path(tbl.getDataLocation().getPath(),"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1224,"FileSystem fs = FileSystem.get(tbl.getDataLocation(), getConf());"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,2170,"LOG.debug((replace ? ""Replacing src:"" : ""Renaming src:"") + srcf.toString()"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,2274,if (oldPath != null && (!destf.getFileSystem(conf).equals(oldPath.getFileSystem(conf))
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,2275,|| !destf.equals(oldPath))) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1765,"throw new HiveException(""Partition spec should only be supplied for a "" +"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1766,"""partitioned table"");"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1819,"throw new HiveException(""Partition spec should only be supplied for a "" +"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1820,"""partitioned table"");"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1844,"throw new HiveException(""Partition spec should only be supplied for a "" +"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1845,"""partitioned table"");"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1896,"throw new HiveException(""Partition spec should only be supplied for a "" +"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1897,"""partitioned table"");"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,2199,"fs.setPermission(destf, fs.getFileStatus(destf.getParent()).getPermission());"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,1213,if (oldPartPathFS.equals(loadPathFS)) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,678,org.apache.hadoop.hive.metastore.api.StorageDescriptor storageDescriptor = baseTbl.getSd().deepCopy();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,679,SerDeInfo serdeInfo = storageDescriptor.getSerdeInfo();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Hive.java,769,"storageDescriptor, params, deferredRebuild);"
ql/src/java/org/apache/hadoop/hive/ql/metadata/HiveMetaStoreChecker.java,257,Path partPath = partition.getPartitionPath();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java,230,Path[] ret = new Path[]{getPartitionPath()};
ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java,234,public Path getPartitionPath() {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java,395,"FileSystem fs = FileSystem.get(getPartitionPath().toUri(), Hive.get()"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java,396,.getConf());
ql/src/java/org/apache/hadoop/hive/ql/metadata/Partition.java,397,String pathPattern = getPartitionPath().toString();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,85,private URI uri;
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,253,final public URI getDataLocation() {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,254,if (uri == null) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,255,Path path = getPath();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,256,if (path != null) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,257,uri = path.toUri();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,260,return uri;
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,501,public void setDataLocation(URI uri) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,502,this.uri = uri;
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,503,tTable.getSd().setLocation(uri.toString());
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,507,this.uri = null;
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,638,Path tableDest =  new Path(getDataLocation().getPath());
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,651,"fs = FileSystem.get(getDataLocation(), Hive.get().getConf());"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,652,"Hive.copyFiles(Hive.get().getConf(), srcf, new Path(getDataLocation().getPath()), fs);"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,328,"c = Class.forName(className, true,"
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,329,JavaUtils.getClassLoader());
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,591,boolean getColsFromSerDe = SerDeUtils.shouldGetColsFromSerDe(
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,592,getSerializationLib());
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,593,if (!getColsFromSerDe) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,594,return tTable.getSd().getCols();
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,595,} else {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,596,try {
ql/src/java/org/apache/hadoop/hive/ql/metadata/Table.java,601,return new ArrayList<FieldSchema>();
ql/src/java/org/apache/hadoop/hive/ql/optimizer/AbstractBucketJoinProc.java,80,"URI location, ParseContext pGraphContext) throws SemanticException {"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/AbstractBucketJoinProc.java,83,"FileSystem fs = FileSystem.get(location, pGraphContext.getConf());"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java,185,part.getPartitionPath().toString() + e.getMessage()));
ql/src/java/org/apache/hadoop/hive/ql/optimizer/GenMRTableScan1.java,143,"PrunedPartitionList partList = new PrunedPartitionList(source, confirmedPartns, false);"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/IndexUtils.java,168,FileSystem partFs = part.getPartitionPath().getFileSystem(hive.getConf());
ql/src/java/org/apache/hadoop/hive/ql/optimizer/IndexUtils.java,169,FileStatus partFss = partFs.getFileStatus(part.getPartitionPath());
ql/src/java/org/apache/hadoop/hive/ql/optimizer/SamplePruner.java,322,"FileSystem fs = FileSystem.get(part.getPartitionPath().toUri(), Hive.get()"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/SamplePruner.java,323,.getConf());
ql/src/java/org/apache/hadoop/hive/ql/optimizer/SamplePruner.java,324,"String pathPattern = part.getPartitionPath().toString() + ""/*"";"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/SizeBasedBigTableSelectorForAutoSMJ.java,81,Path path = partition.getPartitionPath();
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java,161,"authorize(part.getPartitionPath(), readRequiredPriv, writeRequiredPriv);"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java,130,Path path = null;
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java,134,if (location == null || location.isEmpty()) {
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java,135,"path = wh.getTablePath(hive_db.getDatabase(table.getDbName()), table.getTableName());"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java,136,} else {
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/StorageBasedAuthorizationProvider.java,137,path = new Path(location);
ql/src/test/org/apache/hadoop/hive/ql/metadata/TestHiveMetaStoreChecker.java,224,Path partToRemovePath = new Path(partToRemove.getDataLocation().toString());
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,179,return new CommandProcessorResponse(0);
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,186,return new CommandProcessorResponse(0);
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,195,return new CommandProcessorResponse(0);
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,204,return new CommandProcessorResponse(0);
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,213,return new CommandProcessorResponse(0);
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,220,"return new CommandProcessorResponse(0, null, null, getSchema());"
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,231,"return new CommandProcessorResponse(0, null, null, sch);"
ql/src/java/org/apache/hadoop/hive/ql/processors/SetProcessor.java,236,"return new CommandProcessorResponse(0, null, null, sch);"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,440,boolean bigTableFound = false;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,441,long largestBigTableCandidateSize = -1;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,442,long sumTableSizes = 0;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,443,for (String alias : aliasToWork.keySet()) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,445,boolean bigTableCandidate = bigTableCandidates.contains(tablePosition);
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,446,Long size = aliasToSize.get(alias);
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,451,if ((size == null) || (size > mapJoinSize)) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,452,sumTableSizes += largestBigTableCandidateSize;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,453,if (bigTableFound || (sumTableSizes > mapJoinSize) || !bigTableCandidate) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,454,convertJoinMapJoin = false;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,455,break;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,457,bigTableFound = true;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,459,largestBigTableCandidateSize = mapJoinSize + 1;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,460,} else {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,461,if (bigTableCandidate && size > largestBigTableCandidateSize) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,462,bigTablePosition = tablePosition;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,463,sumTableSizes += largestBigTableCandidateSize;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,464,largestBigTableCandidateSize = size;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,600,} else {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,466,sumTableSizes += size;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,468,if (sumTableSizes > mapJoinSize) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,469,convertJoinMapJoin = false;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,470,break;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,480,if (convertJoinMapJoin) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/physical/CommonJoinTaskDispatcher.java,510,bigTableAlias = newTaskAlias.getSecond();
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,74,"return aliasToKnownSize == null ? new HashMap<String, Long>() : aliasToKnownSize;"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,111,ConditionalResolverCommonJoinCtx ctx = (ConditionalResolverCommonJoinCtx) objCtx;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,115,"HashMap<String, ArrayList<String>> pathToAliases = ctx.getPathToAliases();"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,116,"HashMap<String, Long> aliasToKnownSize = ctx.getAliasToKnownSize();"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,117,"String bigTableAlias = this.resolveMapJoinTask(pathToAliases, ctx"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,118,".getAliasToTask(), aliasToKnownSize, ctx.getHdfsTmpDir(), ctx"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,119,".getLocalTmpDir(), conf);"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,138,static class AliasFileSizePair implements Comparable<AliasFileSizePair> {
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,139,String alias;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,140,long size;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,141,"AliasFileSizePair(String alias, long size) {"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,142,super();
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,143,this.alias = alias;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,144,this.size = size;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,146,@Override
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,147,public int compareTo(AliasFileSizePair o) {
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,148,if (o == null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,149,return 1;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,151,return (size < o.size) ? -1 : ((size > o.size) ? 1 : 0);
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,162,long smallTablesFileSizeSum = 0;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,164,"Map<String, AliasFileSizePair> aliasToFileSizeMap = new HashMap<String, AliasFileSizePair>();"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,165,"for (Map.Entry<String, Long> entry : aliasToKnownSize.entrySet()) {"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,166,String alias = entry.getKey();
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,167,"AliasFileSizePair pair = new AliasFileSizePair(alias, entry.getValue());"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,168,"aliasToFileSizeMap.put(alias, pair);"
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,199,List<AliasFileSizePair> aliasFileSizeList = new ArrayList<AliasFileSizePair>(
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,200,aliasToFileSizeMap.values());
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,202,Collections.sort(aliasFileSizeList);
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,205,int idx = aliasFileSizeList.size() - 1;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,206,boolean bigAliasFound = false;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,207,while (idx >= 0) {
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,208,AliasFileSizePair pair = aliasFileSizeList.get(idx);
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,209,String alias = pair.alias;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,210,long size = pair.size;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,211,idx--;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,212,if (!bigAliasFound && aliasToTask.get(alias) != null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,214,bigAliasFound = true;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,215,bigTableFileAlias = alias;
ql/src/java/org/apache/hadoop/hive/ql/plan/ConditionalResolverCommonJoin.java,216,continue;
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,21,import junit.framework.TestCase;
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,23,import org.apache.hadoop.hive.ql.plan.ConditionalResolverCommonJoin.AliasFileSizePair;
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,25,public class TestConditionalResolverCommonJoin extends TestCase {
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,27,public void testAliasFileSizePairCompareTo() {
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,28,"AliasFileSizePair big = new AliasFileSizePair(""big"", 389560034778L);"
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,29,"AliasFileSizePair small = new AliasFileSizePair(""small"", 1647L);"
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,31,"assertEquals(0, big.compareTo(big));"
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,32,"assertEquals(1, big.compareTo(small));"
ql/src/test/org/apache/hadoop/hive/ql/plan/TestConditionalResolverCommonJoin.java,33,"assertEquals(-1, small.compareTo(big));"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,240,"HADOOPMAPFILENAME(""map.input.file"", null),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,241,"HADOOPMAPREDINPUTDIR(""mapred.input.dir"", null),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,242,"HADOOPMAPREDINPUTDIRRECURSIVE(""mapred.input.dir.recursive"", false),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,243,"HADOOPJT(""mapred.job.tracker"", null),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,244,"MAPREDMAXSPLITSIZE(""mapred.max.split.size"", 256000000L),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,245,"MAPREDMINSPLITSIZE(""mapred.min.split.size"", 1L),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,246,"MAPREDMINSPLITSIZEPERNODE(""mapred.min.split.size.per.rack"", 1L),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,247,"MAPREDMINSPLITSIZEPERRACK(""mapred.min.split.size.per.node"", 1L),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,251,"HADOOPNUMREDUCERS(""mapred.reduce.tasks"", -1),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,252,"HADOOPJOBNAME(""mapred.job.name"", null),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,253,"HADOOPSPECULATIVEEXECREDUCERS(""mapred.reduce.tasks.speculative.execution"", true),"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,1143,"""effect. Make sure to provide a valid value for hive.metastore.uris if you are "" +"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,1144,"""connecting to a remote metastore."");"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,113,"HiveConf.ConfVars.METASTORE_AUTO_CREATE_SCHEMA,"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,1158,"setBoolVar(ConfVars.METASTORE_AUTO_CREATE_SCHEMA, false);"
common/src/java/org/apache/hadoop/hive/conf/HiveConf.java,1159,"setBoolVar(ConfVars.METASTORE_FIXED_DATASTORE, true);"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,87,public static long getCountForMapJoinDumpFilePrefix() {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,105,"TableDesc tableDesc = getDefaultTableDesc(Integer.toString(Utilities.ctrlaCode), cols,"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,108,return tableDesc;
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,113,tableDesc.getProperties().setProperty(
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,115,tableDesc.getProperties().setProperty(
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,119,tableDesc.getProperties().setProperty(
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,123,tableDesc.getProperties().setProperty(
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,127,tableDesc.getProperties().setProperty(
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,131,tableDesc.getProperties().setProperty(
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,136,tableDesc.getProperties().setProperty(
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,142,tableDesc.setOutputFileFormatClass(Class.forName(localDirectoryDesc.getOutputFormat()));
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,150,return tableDesc;
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,103,"public static TableDesc getDefaultTableDesc(CreateTableDesc localDirectoryDesc,"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,107,if (localDirectoryDesc == null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,112,if (localDirectoryDesc.getFieldDelim() != null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,114,"serdeConstants.FIELD_DELIM, localDirectoryDesc.getFieldDelim());"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,116,"serdeConstants.SERIALIZATION_FORMAT, localDirectoryDesc.getFieldDelim());"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,118,if (localDirectoryDesc.getLineDelim() != null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,120,"serdeConstants.LINE_DELIM, localDirectoryDesc.getLineDelim());"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,122,if (localDirectoryDesc.getCollItemDelim() != null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,124,"serdeConstants.COLLECTION_DELIM, localDirectoryDesc.getCollItemDelim());"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,126,if (localDirectoryDesc.getMapKeyDelim() != null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,128,"serdeConstants.MAPKEY_DELIM, localDirectoryDesc.getMapKeyDelim());"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,130,if (localDirectoryDesc.getFieldEscape() !=null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,132,"serdeConstants.ESCAPE_CHAR, localDirectoryDesc.getFieldEscape());"
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,134,if (localDirectoryDesc.getSerName() != null) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PlanUtils.java,137,"serdeConstants.SERIALIZATION_LIB, localDirectoryDesc.getSerName());"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1701,readRowIndex();
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,2234,private void readRowIndex() throws IOException {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,2235,long offset = stripes.get(currentStripe).getOffset();
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,2281,readRowIndex();
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,191,List<OrcProto.ColumnEncoding> encoding
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,193,checkEncoding(encoding.get(columnId));
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,248,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,250,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,291,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,293,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,343,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,345,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,396,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,398,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,449,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,451,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,493,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,495,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,540,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,542,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,596,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,598,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,668,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,670,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,671,"data = createIntegerReader(encodings.get(columnId).getKind(),"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,674,"nanos = createIntegerReader(encodings.get(columnId).getKind(),"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,748,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,750,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,802,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,804,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,857,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,861,switch (encodings.get(columnId).getKind()) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,872,encodings.get(columnId).getKind());
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,874,"reader.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,916,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,918,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,922,"lengths = createIntegerReader(encodings.get(columnId).getKind(),"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,995,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,997,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1031,"reader = createIntegerReader(encodings.get(columnId).getKind(),"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1166,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1168,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1171,"field.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1235,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1237,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1242,"field.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1321,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1323,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1324,"lengths = createIntegerReader(encodings.get(columnId).getKind(),"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1328,"elementReader.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1409,List<OrcProto.ColumnEncoding> encodings
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1411,"super.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1412,"lengths = createIntegerReader(encodings.get(columnId).getKind(),"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1416,"keyReader.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1419,"valueReader.startStripe(streams, encodings);"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/RecordReaderImpl.java,1777,"reader.startStripe(streams, stripeFooter.getColumnsList());"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HCatUtil.java,558,"hiveClientCache = new HiveClientCache(hiveConf.getInt(HCatConstants.HCAT_HIVE_CLIENT_EXPIRY_TIME,"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HCatUtil.java,559,DEFAULT_HIVE_CACHE_EXPIRY_TIME_SECONDS));
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,21,import com.google.common.cache.Cache;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,22,import com.google.common.cache.CacheBuilder;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,23,import com.google.common.cache.RemovalListener;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,24,import com.google.common.cache.RemovalNotification;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,37,import javax.security.auth.login.LoginException;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,38,import java.io.IOException;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,39,import java.util.concurrent.Callable;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,40,import java.util.concurrent.ConcurrentMap;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,41,import java.util.concurrent.ExecutionException;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,42,import java.util.concurrent.TimeUnit;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/common/HiveClientCache.java,43,import java.util.concurrent.atomic.AtomicInteger;
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,415,"return RetryingRawStore.getProxy(hiveConf, conf, rawStoreClassName, threadLocalId.get());"
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,378,private Configuration getConf() {
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1644,for (Partition part : parts) {
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1645,"fireMetaStoreAddPartitionEvent(ms, part, null, success);"
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1806,Partition retPtn = null;
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1817,"fireMetaStoreAddPartitionEvent(ms, part, envContext, success);"
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1822,"private void fireMetaStoreAddPartitionEvent(final RawStore ms,"
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1823,"final Partition part, final EnvironmentContext envContext, boolean success)"
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1825,"final Table tbl = ms.getTable(part.getDbName(), part.getTableName());"
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1826,for (MetaStoreEventListener listener : listeners) {
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1828,"new AddPartitionEvent(tbl, part, success, this);"
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,1830,listener.onAddPartition(addPartitionEvent);
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,2477,boolean getColsFromSerDe = SerDeUtils.shouldGetColsFromSerDe(
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,2478,tbl.getSd().getSerdeInfo().getSerializationLib());
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStore.java,2479,if (!getColsFromSerDe) {
metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java,331,return currentTransaction.isActive();
metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java,346,"throw new RuntimeException(""commitTransaction was called but openTransactionCalls = """
metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java,348,"""calls to openTransaction/commitTransaction"");"
metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java,351,throw new RuntimeException(
metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java,352,"""Commit is called, but transaction is not active. Either there are"""
metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java,353,"+ "" mismatching open and close calls or rollback was called in the same trasaction"");"
metastore/src/java/org/apache/hadoop/hive/metastore/ObjectStore.java,550,"return getDatabases("".*"");"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingRawStore.java,42,public class RetryingRawStore implements InvocationHandler {
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingRawStore.java,44,private static final Log LOG = LogFactory.getLog(RetryingRawStore.class);
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingRawStore.java,55,"protected RetryingRawStore(HiveConf hiveConf, Configuration conf,"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingRawStore.java,73,"RetryingRawStore handler = new RetryingRawStore(hiveConf, conf, baseClass, id);"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingRawStore.java,76,"return (RawStore) Proxy.newProxyInstance(RetryingRawStore.class.getClassLoader(),"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java,48,"protected RetryingHMSHandler(HiveConf hiveConf, String name) throws MetaException {"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java,54,"this.base = (IHMSHandler) new HiveMetaStore.HMSHandler(name, hiveConf);"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java,79,"public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java,147,LOG.error(ExceptionUtils.getStackTrace(caughtException));
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java,156,String.format(
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java,157,"""JDO datastore error. Retrying HMSHandler "" +"
metastore/src/java/org/apache/hadoop/hive/metastore/RetryingHMSHandler.java,158,"""after %d ms (attempt %d of %d)"", retryInterval, retryCount, retryLimit));"
ql/src/java/org/apache/hadoop/hive/ql/security/HadoopDefaultMetastoreAuthenticator.java,28,setConf(handler.getHiveConf());
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,62,private static HiveConf conf;
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,63,private static HiveMetastoreAuthorizationProvider authorizer;
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,64,private static HiveMetastoreAuthenticationProvider authenticator;
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,79,authenticator.setMetaStoreHandler(context.getHandler());
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,80,authorizer.setMetaStoreHandler(context.getHandler());
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,119,"authorizer.authorize(new Database(context.getDatabase()),"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,132,"authorizer.authorize(new Database(context.getDatabase()),"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,145,"authorizer.authorize(getTableFromApiTable(context.getTable()),"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,158,"authorizer.authorize(getTableFromApiTable(context.getTable()),"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,171,"authorizer.authorize(getTableFromApiTable(context.getOldTable()),"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,185,"authorizer.authorize(getPartitionFromApiPartition(mapiPart, context),"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,201,"authorizer.authorize(getPartitionFromApiPartition(mapiPart, context),"
ql/src/java/org/apache/hadoop/hive/ql/security/authorization/AuthorizationPreEventListener.java,217,"authorizer.authorize(getPartitionFromApiPartition(mapiPart, context),"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,94,"private static String getTopicName(Partition partition,"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,95,ListenerEvent partitionEvent) throws MetaException {
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,96,try {
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,97,return partitionEvent.getHandler()
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,98,".get_table(partition.getDbName(), partition.getTableName())"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,99,.getParameters().get(HCatConstants.HCAT_MSGBUS_TOPIC_NAME);
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,100,} catch (NoSuchObjectException e) {
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,101,throw new MetaException(e.toString());
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,113,Partition partition = partitionEvent.getPartition();
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,114,"String topicName = getTopicName(partition, partitionEvent);"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,115,"if (topicName != null && !topicName.equals("""")) {"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,116,"send(messageFactory.buildAddPartitionMessage(partitionEvent.getTable(), partition), topicName);"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,117,} else {
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,118,"LOG.info(""Topic name not found in metastore. Suppressing HCatalog notification for """
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,119,#NAME?
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,121,#NAME?
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,122," To enable notifications for this table, please do alter table set properties ("
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,123,#NAME?
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,124,"+ ""=<dbname>.<tablename>) or whatever you want topic name to be."");"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/listener/NotificationListener.java,151,"String topicName = getTopicName(partition, partitionEvent);"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/messaging/MessageFactory.java,130,"public abstract AddPartitionMessage buildAddPartitionMessage(Table table, Partition partition);"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/messaging/json/JSONMessageFactory.java,87,"public AddPartitionMessage buildAddPartitionMessage(Table table, Partition partition) {"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/messaging/json/JSONMessageFactory.java,88,"return new JSONAddPartitionMessage(HCAT_SERVER_URL, HCAT_SERVICE_PRINCIPAL, partition.getDbName(),"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/messaging/json/JSONMessageFactory.java,89,"partition.getTableName(), Arrays.asList(getPartitionKeyValues(table, partition)),"
hcatalog/server-extensions/src/main/java/org/apache/hcatalog/messaging/json/JSONMessageFactory.java,90,System.currentTimeMillis()/1000);
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,117,"private static String getTopicName(Partition partition,"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,118,ListenerEvent partitionEvent) throws MetaException {
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,119,try {
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,120,return partitionEvent.getHandler()
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,121,".get_table(partition.getDbName(), partition.getTableName())"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,122,.getParameters().get(HCatConstants.HCAT_MSGBUS_TOPIC_NAME);
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,123,} catch (NoSuchObjectException e) {
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,124,throw new MetaException(e.toString());
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,136,Partition partition = partitionEvent.getPartition();
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,137,"String topicName = getTopicName(partition, partitionEvent);"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,139,"send(messageFactory.buildAddPartitionMessage(partitionEvent.getTable(), partition), topicName);"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,142,#NAME?
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,144,#NAME?
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,145," To enable notifications for this table, please do alter table set properties ("
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,146,#NAME?
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,147,"+ ""=<dbname>.<tablename>) or whatever you want topic name to be."");"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/listener/NotificationListener.java,174,"String topicName = getTopicName(partition, partitionEvent);"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/MessageFactory.java,129,"public abstract AddPartitionMessage buildAddPartitionMessage(Table table, Partition partition);"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONMessageFactory.java,34,import java.util.Arrays;
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONMessageFactory.java,35,import java.util.LinkedHashMap;
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONMessageFactory.java,36,import java.util.Map;
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONMessageFactory.java,86,"public AddPartitionMessage buildAddPartitionMessage(Table table, Partition partition) {"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONMessageFactory.java,87,"return new JSONAddPartitionMessage(HCAT_SERVER_URL, HCAT_SERVICE_PRINCIPAL, partition.getDbName(),"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONMessageFactory.java,88,"partition.getTableName(), Arrays.asList(getPartitionKeyValues(table, partition)),"
hcatalog/server-extensions/src/main/java/org/apache/hive/hcatalog/messaging/json/JSONMessageFactory.java,89,System.currentTimeMillis()/1000);
metastore/src/java/org/apache/hadoop/hive/metastore/events/AddPartitionEvent.java,28,private final Partition partition;
metastore/src/java/org/apache/hadoop/hive/metastore/events/AddPartitionEvent.java,30,"public AddPartitionEvent (Table table, Partition partition, boolean status, HMSHandler handler) {"
metastore/src/java/org/apache/hadoop/hive/metastore/events/AddPartitionEvent.java,31,"super (status, handler);"
metastore/src/java/org/apache/hadoop/hive/metastore/events/AddPartitionEvent.java,33,this.partition = partition;
metastore/src/java/org/apache/hadoop/hive/metastore/events/AddPartitionEvent.java,39,public Partition getPartition() {
metastore/src/java/org/apache/hadoop/hive/metastore/events/AddPartitionEvent.java,40,return partition;
metastore/src/java/org/apache/hadoop/hive/metastore/events/PreAddPartitionEvent.java,26,private final Partition partition;
metastore/src/java/org/apache/hadoop/hive/metastore/events/PreAddPartitionEvent.java,28,"public PreAddPartitionEvent (Partition partition, HMSHandler handler) {"
metastore/src/java/org/apache/hadoop/hive/metastore/events/PreAddPartitionEvent.java,30,this.partition = partition;
metastore/src/java/org/apache/hadoop/hive/metastore/events/PreAddPartitionEvent.java,36,public Partition getPartition() {
metastore/src/java/org/apache/hadoop/hive/metastore/events/PreAddPartitionEvent.java,37,return partition;
serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/objectinspector/LazyBinaryMapObjectInspector.java,56,if (data == null) {
serde/src/java/org/apache/hadoop/hive/serde2/lazybinary/objectinspector/LazyBinaryMapObjectInspector.java,57,return -1;
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FosterStorageHandler.java,160,"jobProperties.put(RCFile.COLUMN_NUMBER_CONF_STR,"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FosterStorageHandler.java,161,Integer.toOctalString(
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FosterStorageHandler.java,162,jobInfo.getOutputSchema().getFields().size()));
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,107,@Override
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,100,"public RecordWriter<NullWritable, OrcSerdeRow>"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,101,"getRecordWriter(FileSystem fileSystem, JobConf conf, String name,"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,114,Progressable reporter) throws IOException {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,103,return new
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,104,"OrcRecordWriter(new Path(name), OrcFile.writerOptions(conf));"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,116,if (tableProperties.containsKey(OrcFile.STRIPE_SIZE)) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,117,options.stripeSize(Long.parseLong
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,118,(tableProperties.getProperty(OrcFile.STRIPE_SIZE)));
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,121,if (tableProperties.containsKey(OrcFile.COMPRESSION)) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,122,options.compress(CompressionKind.valueOf
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,123,(tableProperties.getProperty(OrcFile.COMPRESSION)));
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,126,if (tableProperties.containsKey(OrcFile.COMPRESSION_BLOCK_SIZE)) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,127,options.bufferSize(Integer.parseInt
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,128,(tableProperties.getProperty
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,129,(OrcFile.COMPRESSION_BLOCK_SIZE)));
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,132,if (tableProperties.containsKey(OrcFile.ROW_INDEX_STRIDE)) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,133,options.rowIndexStride(Integer.parseInt
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,134,(tableProperties.getProperty
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,135,(OrcFile.ROW_INDEX_STRIDE)));
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,138,if (tableProperties.containsKey(OrcFile.ENABLE_INDEXES)) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,139,"if (""false"".equals(tableProperties.getProperty"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,140,(OrcFile.ENABLE_INDEXES))) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,145,if (tableProperties.containsKey(OrcFile.BLOCK_PADDING)) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,146,options.blockPadding(Boolean.parseBoolean
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,147,(tableProperties.getProperty
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,148,(OrcFile.BLOCK_PADDING)));
ql/src/java/org/apache/hadoop/hive/ql/io/orc/OrcOutputFormat.java,151,"return new OrcRecordWriter(path, options);"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,196,try {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,197,if (dynamicPartitioningUsed) {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,198,discoverPartitions(jobContext);
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,201,for (JobContext context : contextDiscoveredByPath.values()) {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,202,new JobConf(context.getConfiguration())
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,203,.getOutputCommitter().commitJob(context);
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,206,if (getBaseOutputCommitter() != null && !dynamicPartitioningUsed) {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,207,getBaseOutputCommitter().commitJob(
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,208,HCatMapRedUtil.createJobContext(jobContext));
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,210,registerPartitions(jobContext);
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,212,OutputJobInfo jobInfo = HCatOutputFormat.getJobInfo(jobContext);
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,213,if (getOutputDirMarking(jobContext.getConfiguration())) {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,214,Path outputPath = new Path(jobInfo.getLocation());
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,215,FileSystem fileSys = outputPath.getFileSystem(jobContext
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,216,.getConfiguration());
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,218,if (fileSys.exists(outputPath)) {
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,219,"Path filePath = new Path(outputPath,"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,220,SUCCEEDED_FILE_NAME);
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,221,if (!fileSys.exists(filePath)) { // may have been
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,224,fileSys.create(filePath).close();
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,724,"LOG.info(""Cancelling deletgation token for the job."");"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/mapreduce/FileOutputCommitterContainer.java,124,return false;
common/src/java/org/apache/hadoop/hive/common/FileUtils.java,292,for (FileStatus stat : fs.listStatus(fileStatus.getPath())) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/JsonMetaDataFormatter.java,213,"putFileSystemsStats(builder, makeTableStatusLocations(tbl, db, par),"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java,459,HadoopJobExecHelper.runningJobKillURIs.remove(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java,385,if (mWork.getSamplingType() > 0 && rWork != null && rWork.getNumReduceTasks() > 1) {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/ExecDriver.java,547,"sampler.writePartitionKeys(partitionFile, job);"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,68,public transient String jobId;
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,69,private LogHelper console;
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,70,private HadoopJobExecHook callBackObj;
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,98,private static String getJobStartMsg(String jobId) {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,108,public static String getJobEndMsg(String jobId) {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,129,public String getJobId() {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,133,public void setJobId(String jobId) {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,155,"public static Map<String, String> runningJobKillURIs = Collections"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,156,".synchronizedMap(new HashMap<String, String>());"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,180,synchronized (runningJobKillURIs) {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,181,for (String uri : runningJobKillURIs.values()) {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,183,"System.err.println(""killing job with: "" + uri);"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,184,java.net.HttpURLConnection conn = (java.net.HttpURLConnection) new java.net.URL(uri)
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,185,.openConnection();
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,186,"conn.setRequestMethod(""POST"");"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,187,int retCode = conn.getResponseCode();
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,188,if (retCode != 200) {
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,189,"System.err.println(""Got an error trying to kill job with URI: "" + uri + "" = """
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,190,+ retCode);
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,193,"System.err.println(""trying to kill job, caught: "" + e);"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,256,TaskReport[] mappers = jc.getMapTaskReports(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,268,TaskReport[] reducers = jc.getReduceTaskReports(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,285,RunningJob newRj = jc.getJob(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,291,"throw new IOException(""Could not find status of job:"" + rj.getJobID());"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,432,"getId(), Keys.TASK_HADOOP_ID, rj.getJobID());"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,434,"console.printInfo(getJobStartMsg(rj.getJobID()) + "", Tracking URL = """
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,437,"+ "" job  -kill "" + rj.getJobID());"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,513,jobId = rj.getJobID();
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,531,"runningJobKillURIs.put(rj.getJobID(), rj.getTrackingURL() + ""&action=kill"");"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,552,String statusMesg = getJobEndMsg(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,602,"ReducerTimeStatsPerJob reducerTimeStatsPerJob = new ReducerTimeStatsPerJob(reducersRunTimes,"
ql/src/java/org/apache/hadoop/hive/ql/exec/mr/HadoopJobExecHelper.java,603,new String(this.jobId));
ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/merge/BlockMergeTask.java,244,HadoopJobExecHelper.runningJobKillURIs.remove(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/stats/PartialScanTask.java,251,HadoopJobExecHelper.runningJobKillURIs.remove(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/io/rcfile/truncate/ColumnTruncateTask.java,220,HadoopJobExecHelper.runningJobKillURIs.remove(rj.getJobID());
ql/src/java/org/apache/hadoop/hive/ql/plan/ReducerTimeStatsPerJob.java,50,"public ReducerTimeStatsPerJob(List<Integer> reducersRunTimes, String jobId) {"
ql/src/java/org/apache/hadoop/hive/ql/plan/ReducerTimeStatsPerJob.java,51,this.jobId = jobId;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,41,import org.apache.hadoop.hive.serde2.objectinspector.primitive.ShortObjectInspector;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,42,import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,43,import org.apache.hadoop.hive.serde2.objectinspector.primitive.TimestampObjectInspector;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,70,if (arguments[0].getTypeName() != serdeConstants.STRING_TYPE_NAME
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,71,&& arguments[0].getTypeName() != serdeConstants.VOID_TYPE_NAME) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,86,return PrimitiveObjectInspectorFactory.writableStringObjectInspector;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,94,String pattern = ((StringObjectInspector) argumentOIs[0])
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,95,.getPrimitiveJavaObject(arguments[0].get());
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,97,ArrayList argumentList = new ArrayList();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,119,argumentList.add(((DoubleObjectInspector)argumentOIs[i]).get(arguments[i].get()));
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,120,break;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,126,argumentList.add(((TimestampObjectInspector)argumentOIs[i])
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFPrintf.java,137,"formatter.format(pattern, argumentList.toArray());"
hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/HCatLoader.java,180,PigHCatUtil.getHCatServerPrincipal(job));
hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/HCatLoader.java,196,PigHCatUtil.getHCatServerPrincipal(job));
hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java,136,"String serverKerberosPrincipal, Class<?> clazz) throws Exception {"
hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java,137,HiveConf hiveConf = new HiveConf(clazz);
hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java,173,"public Table getTable(String location, String hcatServerUri, String hcatServerPrincipal) throws IOException {"
hcatalog/hcatalog-pig-adapter/src/main/java/org/apache/hcatalog/pig/PigHCatUtil.java,186,"client = getHiveMetaClient(hcatServerUri, hcatServerPrincipal, PigHCatUtil.class);"
beeline/src/java/org/apache/hive/beeline/BeeLine.java,541,files.add(args[i]);
beeline/src/java/org/apache/hive/beeline/BeeLine.java,496,boolean initArgs(String[] args) {
beeline/src/java/org/apache/hive/beeline/BeeLine.java,497,List<String> commands = new LinkedList<String>();
beeline/src/java/org/apache/hive/beeline/BeeLine.java,498,List<String> files = new LinkedList<String>();
beeline/src/java/org/apache/hive/beeline/BeeLine.java,1379,return false;
beeline/src/java/org/apache/hive/beeline/BeeLine.java,571,if (commands.size() > 0) {
beeline/src/java/org/apache/hive/beeline/BeeLine.java,579,dispatch(command);
beeline/src/java/org/apache/hive/beeline/BeeLine.java,583,return true;
metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java,1026,return (comment == null || comment.isEmpty()) ? FROM_SERIALIZER : comment;
metastore/src/java/org/apache/hadoop/hive/metastore/MetaStoreUtils.java,904,"HiveMetaStore.startMetaStore(port, bridge);"
ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java,273,"return col.getComment() != null ? col.getComment() : ""None"";"
ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java,84,if ((partCols != null) && (!partCols.isEmpty())) {
ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/MetaDataFormatUtils.java,333,return new TextMetaDataFormatter(conf.getIntVar(HiveConf.ConfVars.CLIPRETTYOUTPUTNUMCOLS));
ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java,394,public void validate()
ql/src/java/org/apache/hadoop/hive/ql/plan/CreateTableDesc.java,400,|| !SerDeUtils.shouldGetColsFromSerDe(this.getSerName())) {
serde/src/java/org/apache/hadoop/hive/serde2/RegexSerDe.java,168,"columnNames, columnOIs);"
ql/src/java/org/apache/hadoop/hive/ql/metadata/formatting/TextMetaDataFormatter.java,63,public TextMetaDataFormatter(int prettyOutputNumCols) {
hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java,300,throw new RuntimeException(
hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java,294,"""Unexpected residual predicate "" + residualPredicate.getExprString());"
hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java,299,if (searchConditions.size() < 1 || searchConditions.size() > 2) {
hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java,293,throw new RuntimeException(
hbase-handler/src/java/org/apache/hadoop/hive/hbase/HiveHBaseTableInputFormat.java,301,"""Either one or two search conditions expected in push down"");"
serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyArrayMapStruct.java,182,"assertEquals(""{'2':'d\\tf','2':'d','-1':null,'0':'0','8':'abc'}"""
serde/src/test/org/apache/hadoop/hive/serde2/lazy/TestLazyArrayMapStruct.java,246,"assertEquals(""{'a':null,'b':['',''],'c':{'':null,'':null},'d':':'}"""
ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBPartitionProcFactory.java,56,ParseContext parseCtx = owc.getParseContext();
ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBPartitionProcFactory.java,57,PrunedPartitionList prunedPartList;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBPartitionProcFactory.java,58,try {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBPartitionProcFactory.java,59,String alias = (String) parseCtx.getTopOps().keySet().toArray()[0];
ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBPartitionProcFactory.java,60,"prunedPartList = PartitionPruner.prune(top, parseCtx, alias);"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBPartitionProcFactory.java,61,} catch (HiveException e) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/listbucketingpruner/LBPartitionProcFactory.java,64,"throw new SemanticException(e.getMessage(), e);"
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java,56,transient HiveConf hiveConf;
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java,67,"hiveConf = new HiveConf(jobConf, PTFOperator.class);"
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java,73,inputPart = createFirstPartitionForChain(
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java,74,"inputObjInspectors[0], hiveConf, isMapOperator);"
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java,141,protected void reconstructQueryDef(HiveConf hiveConf) throws HiveException {
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFOperator.java,261,"HiveConf hiveConf, boolean isMapSide) throws HiveException {"
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFPartition.java,49,"protected PTFPartition(HiveConf cfg,"
ql/src/java/org/apache/hadoop/hive/ql/exec/PTFPartition.java,225,"public static PTFPartition create(HiveConf cfg,"
ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java,94,public HiveConf getCfg() {
ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDesc.java,98,public void setCfg(HiveConf cfg) {
ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDeserializer.java,67,HiveConf hConf;
ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDeserializer.java,70,"public PTFDeserializer(PTFDesc ptfDesc, StructObjectInspector inputOI, HiveConf hConf) {"
ql/src/java/org/apache/hadoop/hive/ql/plan/PTFDeserializer.java,289,"return (TableFunctionResolver) ReflectionUtils.newInstance(rCls, null);"
ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java,248,neededColumnIDs = orign_columns;
ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java,252,return neededColumnIDs;
ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java,256,neededColumns = columnNames;
ql/src/java/org/apache/hadoop/hive/ql/exec/TableScanOperator.java,260,return neededColumns;
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java,316,for (int i = 0; i < cols.size(); i++) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java,317,String[] tabCol = inputRR.reverseLookup(cols.get(i));
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java,318,if(tabCol == null) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java,334,int position = inputRR.getPosition(cols.get(i));
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ColumnPrunerProcFactory.java,338,neededColumnNames.add(cols.get(i));
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java,227,"static private ExprNodeDesc removeNonPartCols(ExprNodeDesc expr, List<String> partCols) {"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java,228,if (expr instanceof ExprNodeColumnDesc
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java,229,&& !partCols.contains(((ExprNodeColumnDesc) expr).getColumn())) {
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java,231,"return new ExprNodeConstantDesc(expr.getTypeInfo(), null);"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java,236,"children.set(i, removeNonPartCols(children.get(i), partCols));"
ql/src/java/org/apache/hadoop/hive/ql/optimizer/ppr/PartitionPruner.java,264,"prunerExpr = removeNonPartCols(prunerExpr, extractPartColNames(tab));"
ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnAccessAnalyzer.java,47,List<FieldSchema> tableCols = table.getCols();
ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnAccessAnalyzer.java,48,for (int i : op.getNeededColumnIDs()) {
ql/src/java/org/apache/hadoop/hive/ql/parse/ColumnAccessAnalyzer.java,49,"columnAccessInfo.add(tableName, tableCols.get(i).getName());"
ql/src/java/org/apache/hadoop/hive/ql/parse/PrunedPartitionList.java,42,"public PrunedPartitionList(Table source, Set<Partition> partitions, boolean hasUnknowns) {"
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesInput.java,85,if (code == Type.BYTES.code) {
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesInput.java,86,return new Buffer(readBytes());
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesInput.java,87,} else if (code == Type.BYTE.code) {
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesOutput.java,80,if (obj instanceof Buffer) {
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesOutput.java,81,writeBytes(((Buffer) obj).get());
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesOutput.java,82,} else if (obj instanceof Byte) {
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordInput.java,31,public class TypedBytesRecordInput implements RecordInput {
contrib/src/java/org/apache/hadoop/hive/contrib/util/typedbytes/TypedBytesRecordOutput.java,33,public class TypedBytesRecordOutput implements RecordOutput {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,48,private double lowValue; // required
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,49,private double highValue; // required
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,129,"tmpMap.put(_Fields.LOW_VALUE, new org.apache.thrift.meta_data.FieldMetaData(""lowValue"", org.apache.thrift.TFieldRequirementType.REQUIRED,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,131,"tmpMap.put(_Fields.HIGH_VALUE, new org.apache.thrift.meta_data.FieldMetaData(""highValue"", org.apache.thrift.TFieldRequirementType.REQUIRED,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,363,boolean this_present_lowValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,364,boolean that_present_lowValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,372,boolean this_present_highValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,373,boolean that_present_highValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,406,boolean present_lowValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,411,boolean present_highValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,497,"sb.append(""lowValue:"");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,498,sb.append(this.lowValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,499,first = false;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,500,"if (!first) sb.append("", "");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,501,"sb.append(""highValue:"");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,502,sb.append(this.highValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,503,first = false;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,618,oprot.writeFieldBegin(LOW_VALUE_FIELD_DESC);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,619,oprot.writeDouble(struct.lowValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,620,oprot.writeFieldEnd();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,621,oprot.writeFieldBegin(HIGH_VALUE_FIELD_DESC);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,622,oprot.writeDouble(struct.highValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/DoubleColumnStatsData.java,623,oprot.writeFieldEnd();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,48,private long lowValue; // required
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,49,private long highValue; // required
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,129,"tmpMap.put(_Fields.LOW_VALUE, new org.apache.thrift.meta_data.FieldMetaData(""lowValue"", org.apache.thrift.TFieldRequirementType.REQUIRED,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,131,"tmpMap.put(_Fields.HIGH_VALUE, new org.apache.thrift.meta_data.FieldMetaData(""highValue"", org.apache.thrift.TFieldRequirementType.REQUIRED,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,363,boolean this_present_lowValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,364,boolean that_present_lowValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,372,boolean this_present_highValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,373,boolean that_present_highValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,406,boolean present_lowValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,411,boolean present_highValue = true;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,497,"sb.append(""lowValue:"");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,498,sb.append(this.lowValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,499,first = false;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,500,"if (!first) sb.append("", "");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,501,"sb.append(""highValue:"");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,502,sb.append(this.highValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,503,first = false;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,618,oprot.writeFieldBegin(LOW_VALUE_FIELD_DESC);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,619,oprot.writeI64(struct.lowValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,620,oprot.writeFieldEnd();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,621,oprot.writeFieldBegin(HIGH_VALUE_FIELD_DESC);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,622,oprot.writeI64(struct.highValue);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/LongColumnStatsData.java,623,oprot.writeFieldEnd();
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,43,private long longLowValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,44,private long longHighValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,45,private double doubleLowValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,46,private double doubleHighValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,167,"public void setLongStats(long numNulls, long numNDVs, long lowValue, long highValue) {"
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,174,"public void setDoubleStats(long numNulls, long numNDVs, double lowValue, double highValue) {"
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,193,public long getLongLowValue() {
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,201,public long getLongHighValue() {
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,209,public double getDoubleLowValue() {
metastore/src/model/org/apache/hadoop/hive/metastore/model/MPartitionColumnStatistics.java,217,public double getDoubleHighValue() {
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,41,private long longLowValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,42,private long longHighValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,43,private double doubleLowValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,44,private double doubleHighValue;
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,157,"public void setLongStats(long numNulls, long numNDVs, long lowValue, long highValue) {"
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,164,"public void setDoubleStats(long numNulls, long numNDVs, double lowValue, double highValue) {"
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,184,public long getLongLowValue() {
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,192,public long getLongHighValue() {
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,200,public double getDoubleLowValue() {
metastore/src/model/org/apache/hadoop/hive/metastore/model/MTableColumnStatistics.java,208,public double getDoubleHighValue() {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,305,public static class GenericUDAFLongStatsEvaluator extends GenericUDAFEvaluator {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,320,private transient StructObjectInspector soi;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,322,private transient StructField minField;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,323,private transient WritableLongObjectInspector minFieldOI;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,325,private transient StructField maxField;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,326,private transient WritableLongObjectInspector maxFieldOI;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,328,private transient StructField countNullsField;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,329,private transient WritableLongObjectInspector countNullsFieldOI;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,331,private transient StructField ndvField;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,332,private transient WritableStringObjectInspector ndvFieldOI;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,334,private transient StructField numBitVectorsField;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,335,private transient WritableIntObjectInspector numBitVectorsFieldOI;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,339,private transient Object[] result;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,353,minFieldOI = (WritableLongObjectInspector) minField.getFieldObjectInspector();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,356,maxFieldOI = (WritableLongObjectInspector) maxField.getFieldObjectInspector();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,373,foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,374,foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,400,foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,401,foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,428,public long min;                              /* Minimum value seen so far */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,429,public long max;                              /* Maximum value seen so far */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,430,public long countNulls;      /* Count of number of null values seen so far */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,431,public LongNumDistinctValueEstimator numDV;    /* Distinct value estimator */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,432,public boolean firstItem;                     /* First item in the aggBuf? */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,433,public int numBitVectors;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,437,return model.primitive1() * 2 + model.primitive2() * 3 +
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,438,model.lengthFor(columnType) + model.lengthFor(numDV);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,442,@Override
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,443,public AggregationBuffer getNewAggregationBuffer() throws HiveException {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,444,LongStatsAgg result = new LongStatsAgg();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,445,reset(result);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,446,return result;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,448,"public void initNDVEstimator(LongStatsAgg aggBuffer, int numBitVectors) {"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,449,aggBuffer.numDV = new LongNumDistinctValueEstimator(numBitVectors);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,450,aggBuffer.numDV.reset();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,453,@Override
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,454,public void reset(AggregationBuffer agg) throws HiveException {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,455,LongStatsAgg myagg = (LongStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,456,"myagg.columnType = new String(""Long"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,457,myagg.min = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,458,myagg.max = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,459,myagg.countNulls = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,460,myagg.firstItem = true;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,463,boolean warned = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,465,@Override
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,466,"public void iterate(AggregationBuffer agg, Object[] parameters) throws HiveException {"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,467,Object p = parameters[0];
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,468,LongStatsAgg myagg = (LongStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,469,boolean emptyTable = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,471,if (parameters[1] == null) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,472,emptyTable = true;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,475,if (myagg.firstItem) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,476,int numVectors = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,477,if (!emptyTable) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,478,"numVectors = PrimitiveObjectInspectorUtils.getInt(parameters[1], numVectorsOI);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,480,"initNDVEstimator(myagg, numVectors);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,481,myagg.firstItem = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,482,myagg.numBitVectors = numVectors;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,488,if (p == null) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,493,"long v = PrimitiveObjectInspectorUtils.getLong(p, inputOI);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,496,if (v < myagg.min) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,497,myagg.min = v;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,501,if (v > myagg.max) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,502,myagg.max = v;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,506,myagg.numDV.addToEstimator(v);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,523,LongStatsAgg myagg = (LongStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,526,Text t = myagg.numDV.serialize();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,529,((Text) partialResult[0]).set(myagg.columnType);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,530,((LongWritable) partialResult[1]).set(myagg.min);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,531,((LongWritable) partialResult[2]).set(myagg.max);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,532,((LongWritable) partialResult[3]).set(myagg.countNulls);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,533,((Text) partialResult[4]).set(t);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,534,((IntWritable) partialResult[5]).set(myagg.numDV.getnumBitVectors());
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,536,return partialResult;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,542,LongStatsAgg myagg = (LongStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,544,if (myagg.firstItem) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,547,"initNDVEstimator(myagg, numVectors);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,548,myagg.firstItem = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,549,myagg.numBitVectors = numVectors;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,554,"Object partialValue = soi.getStructFieldData(partial, minField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,555,if (myagg.min > minFieldOI.get(partialValue)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,556,myagg.min = minFieldOI.get(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,560,"partialValue = soi.getStructFieldData(partial, maxField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,561,if (myagg.max < maxFieldOI.get(partialValue)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,562,myagg.max = maxFieldOI.get(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,566,"partialValue = soi.getStructFieldData(partial, countNullsField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,567,myagg.countNulls += countNullsFieldOI.get(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,570,"partialValue = soi.getStructFieldData(partial, ndvField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,571,String v = ndvFieldOI.getPrimitiveJavaObject(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,572,"NumDistinctValueEstimator o = new NumDistinctValueEstimator(v, myagg.numBitVectors);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,638,"public ObjectInspector init(Mode m, ObjectInspector[] parameters) throws HiveException {"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,639,"super.init(m, parameters);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,642,if (mode == Mode.PARTIAL1 || mode == Mode.COMPLETE) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,643,inputOI = (PrimitiveObjectInspector) parameters[0];
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,644,numVectorsOI = (PrimitiveObjectInspector) parameters[1];
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,645,} else {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,646,soi = (StructObjectInspector) parameters[0];
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,648,"minField = soi.getStructFieldRef(""Min"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,649,minFieldOI = (WritableDoubleObjectInspector) minField.getFieldObjectInspector();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,651,"maxField = soi.getStructFieldRef(""Max"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,652,maxFieldOI = (WritableDoubleObjectInspector) maxField.getFieldObjectInspector();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,654,"countNullsField = soi.getStructFieldRef(""CountNulls"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,655,countNullsFieldOI = (WritableLongObjectInspector) countNullsField.getFieldObjectInspector();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,657,"ndvField = soi.getStructFieldRef(""BitVector"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,658,ndvFieldOI = (WritableStringObjectInspector) ndvField.getFieldObjectInspector();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,660,"numBitVectorsField = soi.getStructFieldRef(""NumBitVectors"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,661,numBitVectorsFieldOI = (WritableIntObjectInspector)
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,662,numBitVectorsField.getFieldObjectInspector();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,666,if (mode == Mode.PARTIAL1 || mode == Mode.PARTIAL2) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,667,List<ObjectInspector> foi = new ArrayList<ObjectInspector>();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,668,foi.add(PrimitiveObjectInspectorFactory.writableStringObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,669,foi.add(PrimitiveObjectInspectorFactory.writableDoubleObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,670,foi.add(PrimitiveObjectInspectorFactory.writableDoubleObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,671,foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,672,foi.add(PrimitiveObjectInspectorFactory.writableStringObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,673,foi.add(PrimitiveObjectInspectorFactory.writableIntObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,675,List<String> fname = new ArrayList<String>();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,676,"fname.add(""ColumnType"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,677,"fname.add(""Min"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,678,"fname.add(""Max"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,679,"fname.add(""CountNulls"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,680,"fname.add(""BitVector"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,681,"fname.add(""NumBitVectors"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,683,partialResult = new Object[6];
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,684,partialResult[0] = new Text();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,685,partialResult[1] = new DoubleWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,686,partialResult[2] = new DoubleWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,687,partialResult[3] = new LongWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,688,partialResult[4] = new Text();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,689,partialResult[5] = new IntWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,691,"return ObjectInspectorFactory.getStandardStructObjectInspector(fname,"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,692,foi);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,693,} else {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,694,List<ObjectInspector> foi = new ArrayList<ObjectInspector>();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,695,foi.add(PrimitiveObjectInspectorFactory.writableStringObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,696,foi.add(PrimitiveObjectInspectorFactory.writableDoubleObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,697,foi.add(PrimitiveObjectInspectorFactory.writableDoubleObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,698,foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,699,foi.add(PrimitiveObjectInspectorFactory.writableLongObjectInspector);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,701,List<String> fname = new ArrayList<String>();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,702,"fname.add(""ColumnType"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,703,"fname.add(""Min"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,704,"fname.add(""Max"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,705,"fname.add(""CountNulls"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,706,"fname.add(""NumDistinctValues"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,708,result = new Object[5];
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,709,result[0] = new Text();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,710,result[1] = new DoubleWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,711,result[2] = new DoubleWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,712,result[3] = new LongWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,713,result[4] = new LongWritable(0);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,715,"return ObjectInspectorFactory.getStandardStructObjectInspector(fname,"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,716,foi);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,721,public static class DoubleStatsAgg extends AbstractAggregationBuffer {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,722,public String columnType;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,723,public double min;                            /* Minimum value seen so far */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,724,public double max;                            /* Maximum value seen so far */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,725,public long countNulls;      /* Count of number of null values seen so far */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,726,public DoubleNumDistinctValueEstimator numDV;  /* Distinct value estimator */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,727,public boolean firstItem;                     /* First item in the aggBuf? */
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,728,public int numBitVectors;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,732,return model.primitive1() * 2 + model.primitive2() * 3 +
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,733,model.lengthFor(columnType) + model.lengthFor(numDV);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,737,@Override
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,738,public AggregationBuffer getNewAggregationBuffer() throws HiveException {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,739,DoubleStatsAgg result = new DoubleStatsAgg();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,740,reset(result);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,741,return result;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,744,"public void initNDVEstimator(DoubleStatsAgg aggBuffer, int numBitVectors) {"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,745,aggBuffer.numDV = new DoubleNumDistinctValueEstimator(numBitVectors);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,746,aggBuffer.numDV.reset();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,749,@Override
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,750,public void reset(AggregationBuffer agg) throws HiveException {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,751,DoubleStatsAgg myagg = (DoubleStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,752,"myagg.columnType = new String(""Double"");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,753,myagg.min = 0.0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,754,myagg.max = 0.0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,755,myagg.countNulls = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,756,myagg.firstItem = true;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,759,boolean warned = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,761,@Override
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,762,"public void iterate(AggregationBuffer agg, Object[] parameters) throws HiveException {"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,763,Object p = parameters[0];
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,764,DoubleStatsAgg myagg = (DoubleStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,765,boolean emptyTable = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,767,if (parameters[1] == null) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,768,emptyTable = true;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,771,if (myagg.firstItem) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,772,int numVectors = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,773,if (!emptyTable) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,774,"numVectors = PrimitiveObjectInspectorUtils.getInt(parameters[1], numVectorsOI);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,776,"initNDVEstimator(myagg, numVectors);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,777,myagg.firstItem = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,778,myagg.numBitVectors = numVectors;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,781,if (!emptyTable) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,784,if (p == null) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,785,myagg.countNulls++;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,787,else {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,788,try {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,790,"double v = PrimitiveObjectInspectorUtils.getDouble(p, inputOI);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,793,if (v < myagg.min) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,794,myagg.min = v;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,798,if (v > myagg.max) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,799,myagg.max = v;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,803,myagg.numDV.addToEstimator(v);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,805,} catch (NumberFormatException e) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,806,if (!warned) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,807,warned = true;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,808,"LOG.warn(getClass().getSimpleName() + "" """
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,809,+ StringUtils.stringifyException(e));
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,810,LOG.warn(getClass().getSimpleName()
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,811,"+ "" ignoring similar exceptions."");"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,819,public Object terminatePartial(AggregationBuffer agg) throws HiveException {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,820,DoubleStatsAgg myagg = (DoubleStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,823,Text t = myagg.numDV.serialize();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,826,((Text) partialResult[0]).set(myagg.columnType);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,827,((DoubleWritable) partialResult[1]).set(myagg.min);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,828,((DoubleWritable) partialResult[2]).set(myagg.max);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,829,((LongWritable) partialResult[3]).set(myagg.countNulls);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,830,((Text) partialResult[4]).set(t);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,831,((IntWritable) partialResult[5]).set(myagg.numBitVectors);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,833,return partialResult;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,837,"public void merge(AggregationBuffer agg, Object partial) throws HiveException {"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,838,if (partial != null) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,839,DoubleStatsAgg myagg = (DoubleStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,841,if (myagg.firstItem) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,842,"Object partialValue = soi.getStructFieldData(partial, numBitVectorsField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,843,int numVectors = numBitVectorsFieldOI.get(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,844,"initNDVEstimator(myagg, numVectors);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,845,myagg.firstItem = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,846,myagg.numBitVectors = numVectors;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,850,"Object partialValue = soi.getStructFieldData(partial, minField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,851,if (myagg.min > minFieldOI.get(partialValue)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,852,myagg.min = minFieldOI.get(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,856,"partialValue = soi.getStructFieldData(partial, maxField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,857,if (myagg.max < maxFieldOI.get(partialValue)) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,858,myagg.max = maxFieldOI.get(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,862,"partialValue = soi.getStructFieldData(partial, countNullsField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,863,myagg.countNulls += countNullsFieldOI.get(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,866,"partialValue = soi.getStructFieldData(partial, ndvField);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,867,String v = ndvFieldOI.getPrimitiveJavaObject(partialValue);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,869,"NumDistinctValueEstimator o = new NumDistinctValueEstimator(v, myagg.numBitVectors);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,870,myagg.numDV.mergeEstimators(o);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,874,@Override
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,875,public Object terminate(AggregationBuffer agg) throws HiveException {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,876,DoubleStatsAgg myagg = (DoubleStatsAgg) agg;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,877,long numDV = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,879,if (myagg.numBitVectors != 0) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,880,numDV = myagg.numDV.estimateNumDistinctValues();
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,884,((Text) result[0]).set(myagg.columnType);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,885,((DoubleWritable) result[1]).set(myagg.min);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,886,((DoubleWritable) result[2]).set(myagg.max);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,887,((LongWritable) result[3]).set(myagg.countNulls);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,888,((LongWritable) result[4]).set(numDV);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1152,if (myagg.firstItem) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1080,int numVectors = 0;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,239,if (!emptyTable) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1082,"numVectors = PrimitiveObjectInspectorUtils.getInt(parameters[1], numVectorsOI);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1155,"initNDVEstimator(myagg, numVectors);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1156,myagg.firstItem = false;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1157,myagg.numBitVectors = numVectors;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1365,if (!emptyTable) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1367,if (p == null) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1368,myagg.countNulls++;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1386,} catch (NumberFormatException e) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1387,if (!warned) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1388,warned = true;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1389,"LOG.warn(getClass().getSimpleName() + "" """
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1390,+ StringUtils.stringifyException(e));
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1391,LOG.warn(getClass().getSimpleName()
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDAFComputeStats.java,1392,"+ "" ignoring similar exceptions."");"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/schema/HCatSchema.java,58,String fieldName = field.getName();
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/schema/HCatSchema.java,60,"throw new IllegalArgumentException(""Field named "" + fieldName +"
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/schema/HCatSchema.java,72,String fieldName = hfs.getName();
hcatalog/core/src/main/java/org/apache/hive/hcatalog/data/schema/HCatSchema.java,96,return fieldPositionMap.get(fieldName);
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTranslate.java,153,"""A string argument was expected but an argument of type "" + arguments[i].getTypeName()"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFTranslate.java,154,"+ "" was given."");"
ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeEvaluatorFactory.java,108,String key = eval.getExpr().getExprString();
ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java,176,Operator<? extends OperatorDesc> op =
ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java,177,(Operator<? extends OperatorDesc>) nd;
ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java,178,ExprNodeDesc predicate = (((FilterOperator) nd).getConf()).getPredicate();
ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java,179,ExprWalkerInfo ewi = new ExprWalkerInfo();
ql/src/java/org/apache/hadoop/hive/ql/ppd/OpProcFactory.java,183,if (!((FilterOperator)op).getConf().getIsSamplingPred()) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToBinary.java,34,"extended = ""Currently only string or binary can be cast into binary"")"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/GenericUDFToBinary.java,57,"throw new UDFArgumentException(""Only string or binary data can be cast into binary "" +"
ql/src/java/org/apache/hadoop/hive/ql/exec/HiveTotalOrderPartitioner.java,29,"public class HiveTotalOrderPartitioner implements Partitioner<HiveKey, Object> {"
ql/src/java/org/apache/hadoop/hive/ql/exec/HiveTotalOrderPartitioner.java,31,"private Partitioner<BytesWritable, Object> partitioner"
ql/src/java/org/apache/hadoop/hive/ql/exec/HiveTotalOrderPartitioner.java,32,"= new TotalOrderPartitioner<BytesWritable, Object>();"
ql/src/java/org/apache/hadoop/hive/ql/exec/HiveTotalOrderPartitioner.java,35,JobConf newconf = new JobConf(job);
ql/src/java/org/apache/hadoop/hive/ql/exec/HiveTotalOrderPartitioner.java,36,newconf.setMapOutputKeyClass(BytesWritable.class);
ql/src/java/org/apache/hadoop/hive/ql/exec/HiveTotalOrderPartitioner.java,37,partitioner.configure(newconf);
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,84,byte[][] partitionKeys = new byte[numReduce - 1][];
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,85,float stepSize = sorted.length / (float) numReduce;
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,86,int last = -1;
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,87,for(int i = 1; i < numReduce; ++i) {
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,88,int k = Math.round(stepSize * i);
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,89,"while (last >= k && C.compare(sorted[last], sorted[k]) == 0) {"
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,90,k++;
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,92,if (k >= sorted.length) {
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,93,"throw new IllegalStateException(""not enough number of sample"");"
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,95,partitionKeys[i - 1] = sorted[k];
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,96,last = k;
ql/src/java/org/apache/hadoop/hive/ql/exec/PartitionKeySampler.java,101,"public void writePartitionKeys(Path path, JobConf job) throws IOException {"
ql/src/java/org/apache/hadoop/hive/ql/exec/Utilities.java,266,if (ShimLoader.getHadoopShims().isLocalMode(conf)) {
ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java,28,private boolean enable = false;
ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java,29,private int globalLimit = -1;
ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java,30,private boolean hasTransformOrUDTF = false;
ql/src/java/org/apache/hadoop/hive/ql/parse/GlobalLimitCtx.java,31,private LimitDesc lastReduceLimitDesc = null;
ql/src/java/org/apache/hadoop/hive/ql/parse/SemanticAnalyzerFactory.java,226,"return new ColumnStatsSemanticAnalyzer(conf, tree);"
ql/src/java/org/apache/hadoop/hive/ql/hooks/HookContext.java,147,return SessionState.get().getHiveOperation().name();
serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java,281,"Map<Utf8, Object> mapDatum = (Map)datum;"
serde/src/java/org/apache/hadoop/hive/serde2/avro/AvroDeserializer.java,284,for (Utf8 key : mapDatum.keySet()) {
cli/src/java/org/apache/hadoop/hive/cli/CliDriver.java,122,this.processFile(cmd_1);
ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeGenericFuncEvaluator.java,116,"deferredChildren[i] = new DeferredExprObject(children[i], isEager);"
ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeGenericFuncEvaluator.java,193,for (int i = 0; i < deferredChildren.length; i++) {
ql/src/java/org/apache/hadoop/hive/ql/exec/ExprNodeGenericFuncEvaluator.java,164,deferredChildren[i].prepare(version);
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,10891,case 64002: {
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11016,return ((bitField0_ & 0x00000010) == 0x00000010);
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,10726,"magic_ = """";"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,3842,bitField0_ |= 0x00000020;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,10151,return ((bitField0_ & 0x00000020) == 0x00000020);
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,3853,bitField0_ |= 0x00000020;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,10163,bitField0_ = (bitField0_ & ~0x00000020);
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,10157,bitField0_ |= 0x00000020;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,121,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,304,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,573,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,756,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,1021,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,1230,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,1487,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,1652,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,1890,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,2139,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,2449,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,2614,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,2870,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,3143,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,4042,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,4229,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,4584,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,4741,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,5137,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,5408,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,5686,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,5930,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,6185,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,6383,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,7031,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,7378,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,7788,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,8007,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,8342,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,8537,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,8841,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,9170,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,10431,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,10691,return org.apache.hadoop.hive.ql.io.orc.OrcProto.internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11061,internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11064,internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11066,internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11069,internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11071,internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11074,internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11076,internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11079,internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11081,internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11084,internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11086,internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11089,internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11091,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11094,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11096,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11099,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11101,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11104,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11106,internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11109,internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11111,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11114,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11116,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11119,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11121,internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11124,internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11126,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11129,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11131,internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11134,internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11136,internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11139,internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11141,internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11144,internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable;
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11229,internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11231,internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11233,"internal_static_org_apache_hadoop_hive_ql_io_orc_IntegerStatistics_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11237,internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11239,internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11241,"internal_static_org_apache_hadoop_hive_ql_io_orc_DoubleStatistics_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11245,internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11247,internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11249,"internal_static_org_apache_hadoop_hive_ql_io_orc_StringStatistics_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11253,internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11255,internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11257,"internal_static_org_apache_hadoop_hive_ql_io_orc_BucketStatistics_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11261,internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11263,internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11265,"internal_static_org_apache_hadoop_hive_ql_io_orc_DecimalStatistics_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11269,internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11271,internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11273,"internal_static_org_apache_hadoop_hive_ql_io_orc_DateStatistics_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11277,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11279,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11281,"internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnStatistics_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11285,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11287,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11289,"internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndexEntry_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11293,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11295,internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11297,"internal_static_org_apache_hadoop_hive_ql_io_orc_RowIndex_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11301,internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11303,internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11305,"internal_static_org_apache_hadoop_hive_ql_io_orc_Stream_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11309,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11311,internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11313,"internal_static_org_apache_hadoop_hive_ql_io_orc_ColumnEncoding_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11317,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11319,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11321,"internal_static_org_apache_hadoop_hive_ql_io_orc_StripeFooter_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11325,internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11327,internal_static_org_apache_hadoop_hive_ql_io_orc_Type_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11329,"internal_static_org_apache_hadoop_hive_ql_io_orc_Type_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11333,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11335,internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11337,"internal_static_org_apache_hadoop_hive_ql_io_orc_StripeInformation_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11341,internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11343,internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11345,"internal_static_org_apache_hadoop_hive_ql_io_orc_UserMetadataItem_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11349,internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11351,internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11353,"internal_static_org_apache_hadoop_hive_ql_io_orc_Footer_descriptor,"
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11357,internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor =
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11359,internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_fieldAccessorTable = new
ql/src/gen/protobuf/gen-java/org/apache/hadoop/hive/ql/io/orc/OrcProto.java,11361,"internal_static_org_apache_hadoop_hive_ql_io_orc_PostScript_descriptor,"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java,383,} else if (maximum.compareTo(str.maximum) < 0) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/ColumnStatisticsImpl.java,488,} else if (maximum.compareTo(dec.maximum) < 0) {
ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java,1817,.addVersion(version.getMinor());
ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java,1109,static final long BASE_TIMESTAMP =
ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java,1110,"Timestamp.valueOf(""2015-01-01 00:00:00"").getTime() / MILLIS_PER_SECOND;"
ql/src/java/org/apache/hadoop/hive/ql/io/orc/WriterImpl.java,1147,seconds.write((val.getTime() / MILLIS_PER_SECOND) - BASE_TIMESTAMP);
metastore/src/java/org/apache/hadoop/hive/metastore/HiveMetaStoreClient.java,541,"dropTable(name, table, deleteData, false);"
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java,45,Coord o = (Coord) other;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java,46,if(x < o.x) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java,47,return -1;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java,49,if(x > o.x) {
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java,50,return 1;
ql/src/java/org/apache/hadoop/hive/ql/udf/generic/NumericHistogram.java,52,return 0;
ql/src/java/org/apache/hadoop/hive/ql/plan/GroupByDesc.java,86,"this(mode, outputColumnNames, keys, aggregators, groupKeyNotReductionKey,"
ql/src/java/org/apache/hadoop/hive/ql/exec/MapOperator.java,469,if (onepath.toUri().relativize(fpath.toUri()).equals(fpath.toUri())) {
beeline/src/java/org/apache/hive/beeline/Commands.java,702,String sql = line;
beeline/src/java/org/apache/hive/beeline/Commands.java,704,if (sql.startsWith(BeeLine.COMMAND_PREFIX)) {
beeline/src/java/org/apache/hive/beeline/Commands.java,705,sql = sql.substring(1);
beeline/src/java/org/apache/hive/beeline/Commands.java,708,"String prefix = call ? ""call"" : ""sql"";"
beeline/src/java/org/apache/hive/beeline/Commands.java,710,if (sql.startsWith(prefix)) {
beeline/src/java/org/apache/hive/beeline/Commands.java,711,sql = sql.substring(prefix.length());
beeline/src/java/org/apache/hive/beeline/Commands.java,715,if (beeLine.getBatch() != null) {
beeline/src/java/org/apache/hive/beeline/Commands.java,716,beeLine.getBatch().add(sql);
beeline/src/java/org/apache/hive/beeline/Commands.java,717,return true;
beeline/src/java/org/apache/hive/beeline/Commands.java,740,try {
beeline/src/java/org/apache/hive/beeline/Commands.java,725,long start = System.currentTimeMillis();
beeline/src/java/org/apache/hive/beeline/Commands.java,735,beeLine.showWarnings();
beeline/src/java/org/apache/hive/beeline/Commands.java,737,if (hasResults) {
beeline/src/java/org/apache/hive/beeline/Commands.java,738,do {
beeline/src/java/org/apache/hive/beeline/Commands.java,739,ResultSet rs = stmnt.getResultSet();
beeline/src/java/org/apache/hive/beeline/Commands.java,1189,try {
beeline/src/java/org/apache/hive/beeline/Commands.java,741,int count = beeLine.print(rs);
beeline/src/java/org/apache/hive/beeline/Commands.java,742,long end = System.currentTimeMillis();
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1086,result = new Timestamp(((BooleanObjectInspector) oi).get(o) ? 1 : 0);
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1089,result = new Timestamp(((ByteObjectInspector) oi).get(o));
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1092,result = new Timestamp(((ShortObjectInspector) oi).get(o));
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1095,result = new Timestamp(((IntObjectInspector) oi).get(o));
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1098,result = new Timestamp(((LongObjectInspector) oi).get(o));
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1101,result = TimestampWritable.floatToTimestamp(((FloatObjectInspector) oi).get(o));
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,982,switch (oi.getPrimitiveCategory()) {
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1104,result = TimestampWritable.doubleToTimestamp(((DoubleObjectInspector) oi).get(o));
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1107,result = TimestampWritable.decimalToTimestamp(((HiveDecimalObjectInspector) oi)
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1043,StringObjectInspector soi = (StringObjectInspector) oi;
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1116,"result = getTimestampFromString(getString(o, oi));"
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1120,((DateObjectInspector) oi).getPrimitiveWritableObject(o).get().getTime());
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1123,result = ((TimestampObjectInspector) oi).getPrimitiveWritableObject(o).getTimestamp();
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorUtils.java,1027,+ oi.getTypeName());
serde/src/java/org/apache/hadoop/hive/serde2/io/DateWritable.java,137,return (int)(millisUtc / MILLIS_PER_DAY);
serde/src/java/org/apache/hadoop/hive/serde2/typeinfo/TypeInfoUtils.java,733,if (typeA == typeB) {
serde/src/java/org/apache/hadoop/hive/serde2/objectinspector/primitive/PrimitiveObjectInspectorConverter.java,282,inputOI));
ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java,56,private CreateTableDesc localDirectoryDesc = null ;
ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java,242,public CreateTableDesc getLLocalDirectoryDesc() {
ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java,243,return localDirectoryDesc;
ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java,246,public void setLocalDirectoryDesc(CreateTableDesc localDirectoryDesc) {
ql/src/java/org/apache/hadoop/hive/ql/parse/QB.java,247,this.localDirectoryDesc = localDirectoryDesc;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24227,private static class drop_table_with_environment_context_resultStandardSchemeFactory implements SchemeFactory {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24228,public drop_table_with_environment_context_resultStandardScheme getScheme() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24229,return new drop_table_with_environment_context_resultStandardScheme();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24233,private static class drop_table_with_environment_context_resultStandardScheme extends StandardScheme<drop_table_with_environment_context_result> {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24235,"public void read(org.apache.thrift.protocol.TProtocol iprot, drop_table_with_environment_context_result struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,35100,case 1: // O1
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,101209,if (schemeField.type == org.apache.thrift.protocol.TType.STRUCT) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,10001,struct.o1 = new NoSuchObjectException();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,9060,struct.o1.read(iprot);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,9061,struct.setO1IsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24254,case 2: // O3
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,9077,struct.o3 = new MetaException();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,9078,struct.o3.read(iprot);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,9079,struct.setO3IsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24272,"public void write(org.apache.thrift.protocol.TProtocol oprot, drop_table_with_environment_context_result struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24292,private static class drop_table_with_environment_context_resultTupleSchemeFactory implements SchemeFactory {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24293,public drop_table_with_environment_context_resultTupleScheme getScheme() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24294,return new drop_table_with_environment_context_resultTupleScheme();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24298,private static class drop_table_with_environment_context_resultTupleScheme extends TupleScheme<drop_table_with_environment_context_result> {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24301,"public void write(org.apache.thrift.protocol.TProtocol prot, drop_table_with_environment_context_result struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,101257,if (struct.isSetO1()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,88083,if (struct.isSetO3()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24320,"public void read(org.apache.thrift.protocol.TProtocol prot, drop_table_with_environment_context_result struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,88100,struct.o1 = new NoSuchObjectException();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,101268,struct.o1.read(iprot);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,101269,struct.setO1IsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,82500,struct.o3 = new MetaException();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,88111,struct.o3.read(iprot);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,88112,struct.setO3IsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39190,"private static final org.apache.thrift.protocol.TField DB_NAME_FIELD_DESC = new org.apache.thrift.protocol.TField(""db_name"", org.apache.thrift.protocol.TType.STRING, (short)1);"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24342,"private static final org.apache.thrift.protocol.TField PATTERN_FIELD_DESC = new org.apache.thrift.protocol.TField(""pattern"", org.apache.thrift.protocol.TType.STRING, (short)2);"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24346,"schemes.put(StandardScheme.class, new get_tables_argsStandardSchemeFactory());"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24347,"schemes.put(TupleScheme.class, new get_tables_argsTupleSchemeFactory());"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39201,private String db_name; // required
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24351,private String pattern; // required
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39208,"DB_NAME((short)1, ""db_name""),"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24356,"PATTERN((short)2, ""pattern"");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,87230,case 1: // DB_NAME
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39227,return DB_NAME;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24373,case 2: // PATTERN
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24374,return PATTERN;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39277,"tmpMap.put(_Fields.DB_NAME, new org.apache.thrift.meta_data.FieldMetaData(""db_name"", org.apache.thrift.TFieldRequirementType.DEFAULT,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24420,"tmpMap.put(_Fields.PATTERN, new org.apache.thrift.meta_data.FieldMetaData(""pattern"", org.apache.thrift.TFieldRequirementType.DEFAULT,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24423,"org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_tables_args.class, metaDataMap);"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24426,public get_tables_args() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24429,public get_tables_args(
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39293,"String db_name,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24431,String pattern)
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,86916,this.db_name = db_name;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24435,this.pattern = pattern;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24441,public get_tables_args(get_tables_args other) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39309,if (other.isSetDb_name()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39310,this.db_name = other.db_name;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24445,if (other.isSetPattern()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24446,this.pattern = other.pattern;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24450,public get_tables_args deepCopy() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24451,return new get_tables_args(this);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,17712,this.db_name = null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24457,this.pattern = null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39335,public String getDb_name() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39336,return this.db_name;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39339,public void setDb_name(String db_name) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39299,this.db_name = db_name;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39343,public void unsetDb_name() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,86930,this.db_name = null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39348,public boolean isSetDb_name() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39349,return this.db_name != null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39352,public void setDb_nameIsSet(boolean value) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39329,this.db_name = null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24483,public String getPattern() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24484,return this.pattern;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24487,public void setPattern(String pattern) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24488,this.pattern = pattern;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24491,public void unsetPattern() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,11344,this.pattern = null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24496,public boolean isSetPattern() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24497,return this.pattern != null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24500,public void setPatternIsSet(boolean value) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24502,this.pattern = null;
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,17764,case DB_NAME:
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39431,unsetDb_name();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39433,setDb_name((String)value);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24516,case PATTERN:
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24518,unsetPattern();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24520,setPattern((String)value);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,87031,case DB_NAME:
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39467,return getDb_name();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,11372,case PATTERN:
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24533,return getPattern();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39429,case DB_NAME:
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39490,return isSetDb_name();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24548,case PATTERN:
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24549,return isSetPattern();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24558,if (that instanceof get_tables_args)
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24559,return this.equals((get_tables_args)that);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24563,public boolean equals(get_tables_args that) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39514,boolean this_present_db_name = true && this.isSetDb_name();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39515,boolean that_present_db_name = true && that.isSetDb_name();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39516,if (this_present_db_name || that_present_db_name) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39517,if (!(this_present_db_name && that_present_db_name))
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39519,if (!this.db_name.equals(that.db_name))
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24576,boolean this_present_pattern = true && this.isSetPattern();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24577,boolean that_present_pattern = true && that.isSetPattern();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24578,if (this_present_pattern || that_present_pattern) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24579,if (!(this_present_pattern && that_present_pattern))
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24581,if (!this.pattern.equals(that.pattern))
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24605,public int compareTo(get_tables_args other) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24650,"StringBuilder sb = new StringBuilder(""get_tables_args("");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39648,"sb.append(""db_name:"");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39649,if (this.db_name == null) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39652,sb.append(this.db_name);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24661,"sb.append(""pattern:"");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24662,if (this.pattern == null) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24665,sb.append(this.pattern);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24693,private static class get_tables_argsStandardSchemeFactory implements SchemeFactory {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24694,public get_tables_argsStandardScheme getScheme() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24695,return new get_tables_argsStandardScheme();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24699,private static class get_tables_argsStandardScheme extends StandardScheme<get_tables_args> {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24701,"public void read(org.apache.thrift.protocol.TProtocol iprot, get_tables_args struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39226,case 1: // DB_NAME
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,87326,struct.db_name = iprot.readString();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,87327,struct.setDb_nameIsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24719,case 2: // PATTERN
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24721,struct.pattern = iprot.readString();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24722,struct.setPatternIsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24736,"public void write(org.apache.thrift.protocol.TProtocol oprot, get_tables_args struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39771,if (struct.db_name != null) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39772,oprot.writeFieldBegin(DB_NAME_FIELD_DESC);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,87311,oprot.writeString(struct.db_name);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24745,if (struct.pattern != null) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24746,oprot.writeFieldBegin(PATTERN_FIELD_DESC);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24747,oprot.writeString(struct.pattern);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24756,private static class get_tables_argsTupleSchemeFactory implements SchemeFactory {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24757,public get_tables_argsTupleScheme getScheme() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24758,return new get_tables_argsTupleScheme();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24762,private static class get_tables_argsTupleScheme extends TupleScheme<get_tables_args> {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24765,"public void write(org.apache.thrift.protocol.TProtocol prot, get_tables_args struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,87310,if (struct.isSetDb_name()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24771,if (struct.isSetPattern()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,100531,"oprot.writeBitSet(optionals, 2);"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39809,if (struct.isSetDb_name()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39773,oprot.writeString(struct.db_name);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24778,if (struct.isSetPattern()) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24779,oprot.writeString(struct.pattern);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24784,"public void read(org.apache.thrift.protocol.TProtocol prot, get_tables_args struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,100543,BitSet incoming = iprot.readBitSet(2);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39727,struct.db_name = iprot.readString();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,39728,struct.setDb_nameIsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24792,struct.pattern = iprot.readString();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24793,struct.setPatternIsSet(true);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24808,"schemes.put(StandardScheme.class, new get_tables_resultStandardSchemeFactory());"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24809,"schemes.put(TupleScheme.class, new get_tables_resultTupleSchemeFactory());"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29051,private List<String> success; // required
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,98376,new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING))));
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24886,"org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(get_tables_result.class, metaDataMap);"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24889,public get_tables_result() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24892,public get_tables_result(
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29144,"List<String> success,"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24904,public get_tables_result(get_tables_result other) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24917,public get_tables_result deepCopy() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,24918,return new get_tables_result(this);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29194,public java.util.Iterator<String> getSuccessIterator() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29198,public void addToSuccess(String elem) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29200,this.success = new ArrayList<String>();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29205,public List<String> getSuccess() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29209,public void setSuccess(List<String> success) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,29303,setSuccess((List<String>)value);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25040,if (that instanceof get_tables_result)
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25041,return this.equals((get_tables_result)that);
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25045,public boolean equals(get_tables_result that) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25087,public int compareTo(get_tables_result other) {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25132,"StringBuilder sb = new StringBuilder(""get_tables_result("");"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25175,private static class get_tables_resultStandardSchemeFactory implements SchemeFactory {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25176,public get_tables_resultStandardScheme getScheme() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25177,return new get_tables_resultStandardScheme();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25181,private static class get_tables_resultStandardScheme extends StandardScheme<get_tables_result> {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25183,"public void read(org.apache.thrift.protocol.TProtocol iprot, get_tables_result struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25229,"public void write(org.apache.thrift.protocol.TProtocol oprot, get_tables_result struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25256,private static class get_tables_resultTupleSchemeFactory implements SchemeFactory {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25257,public get_tables_resultTupleScheme getScheme() {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25258,return new get_tables_resultTupleScheme();
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25262,private static class get_tables_resultTupleScheme extends TupleScheme<get_tables_result> {
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25265,"public void write(org.apache.thrift.protocol.TProtocol prot, get_tables_result struct) throws org.apache.thrift.TException {"
metastore/src/gen/thrift/gen-javabean/org/apache/hadoop/hive/metastore/api/ThriftHiveMetastore.java,25290,"public void read(org.apache.thrift.protocol.TProtocol prot, get_tables_result struct) throws org.apache.thrift.TException {"
service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java,44,private final List<String> tableTypes = new ArrayList<String>();
service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java,54,".addStringColumn(""REMARKS"", ""Comments about the table."");"
service/src/java/org/apache/hive/service/cli/operation/GetTablesOperation.java,68,this.tableTypes.addAll(tableTypes);
service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java,87,"private String convertPattern(final String pattern, boolean datanucleusFormat) {"
service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java,94,return pattern
service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java,95,".replaceAll(""([^\\\\])%"", ""$1"" + wStr).replaceAll(""\\\\%"", ""%"").replaceAll(""^%"", wStr)"
service/src/java/org/apache/hive/service/cli/operation/MetadataOperation.java,96,".replaceAll(""([^\\\\])_"", ""$1."").replaceAll(""\\\\_"", ""_"").replaceAll(""^_"", ""."");"